{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [
        {
          "file_id": "1RRdtIXCXptv_MtW94GGwqyNyeEaCWKNS",
          "timestamp": 1726883346218
        }
      ],
      "name": "[MASTER-Colab-Ent]_Notebook_Automated_Banner_Generation.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Section - About Code"
      ],
      "metadata": {
        "id": "XzNQPGgkvnw4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fyEC9Gs311x"
      },
      "outputs": [],
      "source": [
        "# Section - CoLab Description\n",
        "\n",
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "# Author - shankyram@\n",
        "\n",
        "# Contributor Attribution\n",
        "# This code uses prompts designed by kkrish\n",
        "# Thanks to PSO team members gopalad dsharmila for pointing me to open cv, rembg libraries\n",
        "\n",
        "# Last Updated On - 31 Oct 2024\n",
        "\n",
        "# Solution to demonstrate a banner generation pipeline with\n",
        "## Imagen3 for actor asset creation\n",
        "## Python & Gradio frontend to\n",
        "##    * Imagen3 generated actor assets for target segments\n",
        "##    * Pipeline action to remove actor asset background for overlay placement\n",
        "##    * UI for design banner layout & multi text or image design placement\n",
        "##    * UI for campaign definition for auto banner creation\n",
        "## Leveraging libraries like pillow, cv2, rembg, SAM & Imagen models\n",
        "\n",
        "## Introduction\n",
        "# This demo showcases a cutting-edge solution for hyper-personalized banner generation, designed to revolutionize your telecom Customer Value Management (CVM) strategies. By leveraging AI and a dynamic approach, we can create highly targeted and engaging banners that resonate with individual customer segments, driving conversions and enhancing brand loyalty.\n",
        "# The Problem: Traditional banner campaigns often rely on generic messaging and visuals, resulting in low engagement and limited impact. Customers are bombarded with irrelevant ads, leading to banner blindness and missed opportunities.\n",
        "# Our Solution: This innovative platform utilizes AI-powered image generation and dynamic banner assembly to create hyper-personalized experiences. Imagine banners that feature:\n",
        "# Contexual faces: Actors that reflect the age, ethnicity, and lifestyle of specific customer segments.\n",
        "# Personalized offers: Product recommendations and promotions tailored to individual needs and preferences.\n",
        "# Dynamic backgrounds: Visually appealing scenes that resonate with customer interests and demographics.\n",
        "\n",
        "## Setup Instructions\n",
        "\n",
        "# 1. Create two GCS bucket following\n",
        "  # this format - “<Project Number>_telecom_demo_artefacts_bannergen_input\n",
        "  # this format - “<Project Number>_telecom_demo_artefacts_bannergen_runtime\n",
        "  # In the above example this is - 554686566379_telecom_demo_artefacts_bannergen_input\n",
        "\n",
        "  # Down the entire “Artefacts” and\n",
        "  # upload them into the “ bucket\n",
        "  # Take note to upload the entire “Artefacts” folder as shown below\n",
        "\n",
        "# 2. Create a new Firestore instance “banner-gen-app” in Native mode with Database ID “banner-gen-app”\n",
        "\n",
        "# 3. If you need to update new banner templates, or logos etc, update into the bucket directory \"*telecom_demo_artefacts_bannergen_input - /Logo\" or /Background or /Actors (to bring your own talent images)\"\n",
        "# 4. Please ensure there is nothing uploaded in \"_telecom_demo_artefacts_bannergen_input/Background_Processed\" since this will automatically be done in notebook code\n",
        "# 5. If you add new assets into \"_telecom_demo_artefacts_bannergen_input\" in \"Actors\" / \"Background\", \"Graphics\", \"Logo\", ensure that you rerun the colab from Section - Demo Configuration & Initialization\n",
        "# 6. The contents of \"_telecom_demo_artefacts_bannergen_input/Config\" are for bootstrapping only and subsequently are updated into the firebase DB\n",
        "\n",
        "# 7. Note that all output images generated are temporarily retained in colab local dir and will NOT be saved on colab termination. If you want to reuse them, download them from the folder /content/demo/output for future reference.\n",
        "\n",
        "## Execution Instructions\n",
        "\n",
        "# Step 1: Demo Asset Library\n",
        "# Explore the building blocks of dynamic banners, including a diverse library of actors, backgrounds, logos, graphics, and text elements.\n",
        "# Remember to click on the check box in file explorer not the arrow since the UX components seem to have a better experience with checkbox\n",
        "\n",
        "# Step 2: Demo Asset Creation\n",
        "# Witness the creation of new visual segments aligned with your specific customer targeting needs.\n",
        "# See how AI-powered image generation (Imagen3) can be used to create realistic and diverse actors.\n",
        "# Remember to save the images to the library for the visual segment to be saved in database and images to be available for banner generation\n",
        "\n",
        "# Step 3: Demo Asset Preprocessing\n",
        "# Understand the importance of background removal for seamless integration of actors and elements onto banner templates.\n",
        "# Remember to preprocess newly created visual assets for removing background\n",
        "# Remember logos and graphic elements are expected to be already having transparent background\n",
        "\n",
        "# Step 4: Demo Banner Template Configuration\n",
        "# Learn how banner templates can be defined using intuitive UX providing flexibility and creative control.\n",
        "# Remember that this is configuration controlling placement of text and images in output. Use the tool selection options to define where text header / body and various graphic elements need to be placed\n",
        "\n",
        "# Step 5: Demo Banner Generation\n",
        "# Experience the magic of dynamic banner generation, where personalized banners are automatically created for multiple templates and visual segments.\n",
        "# Remember to click on refresh visual segment to reload the dropdown for reflecting new visual segments\n",
        "\n",
        "## Code Updates\n",
        "# 31 Oct 2024\n",
        "#  - Added fix to support new banner templates to be loaded via upload to GCS bucket (see setup instruction 3 above)\n",
        "#  - Added fix to refresh visual segment\n",
        "#  - Added fix to leave some of image / text inputs in banner generation empty"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section - Code (Global Pre-req - Installs)\n",
        "\n"
      ],
      "metadata": {
        "id": "Xh1_kFoE0rhp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Authenticate Profile\n",
        "\n",
        "# Authentication with Google Account\n",
        "from google.colab import auth as google_auth_profile\n",
        "google_auth_profile.authenticate_user()"
      ],
      "metadata": {
        "id": "w6oruHHVqldq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Install Required Libraries\n",
        "\n",
        "print ('\\nINFO. Installing required libraries.\\n')\n",
        "\n",
        "\n",
        "# Langchain & other libraries\n",
        "!pip install IPython\n",
        "\n",
        "!pip install opencv-python\n",
        "!pip install Pillow\n",
        "!pip install rembg\n",
        "!pip install matplotlib\n",
        "!pip install pyfonts\n",
        "# !pip install torch torchvision segment-anything\n",
        "\n",
        "!pip install gradio_image_annotation\n",
        "!pip install --upgrade gradio \"gradio<5.0,>=4.29\"\n",
        "!pip install gradio_image_annotation\n",
        "\n",
        "!pip install --upgrade --user --quiet google-cloud-aiplatform\n",
        "\n",
        "print ('\\nINFO. Installed all libraries. RESTARTING runtime.\\n')\n",
        "\n",
        "# Automatically restart runtime post library imports\n",
        "import IPython\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ],
      "metadata": {
        "id": "1TzCYBeusdwi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730341275249,
          "user_tz": -480,
          "elapsed": 88200,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "ad48f77c-11a8-48d4-8be4-97a2d9784336"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "INFO. Installing required libraries.\n",
            "\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.10/dist-packages (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from IPython) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from IPython) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from IPython) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from IPython) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from IPython) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from IPython) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from IPython) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from IPython) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from IPython) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from IPython) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->IPython) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->IPython) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython) (0.2.13)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: rembg in /usr/local/lib/python3.10/dist-packages (2.0.59)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from rembg) (4.19.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rembg) (1.25.2)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.10/dist-packages (from rembg) (1.19.2)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from rembg) (4.10.0.84)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from rembg) (9.4.0)\n",
            "Requirement already satisfied: pooch in /usr/local/lib/python3.10/dist-packages (from rembg) (1.8.2)\n",
            "Requirement already satisfied: pymatting in /usr/local/lib/python3.10/dist-packages (from rembg) (1.1.12)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from rembg) (0.19.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from rembg) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from rembg) (4.66.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->rembg) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->rembg) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->rembg) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->rembg) (0.19.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime->rembg) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime->rembg) (24.3.25)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime->rembg) (24.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime->rembg) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime->rembg) (1.13.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch->rembg) (4.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch->rembg) (2.31.0)\n",
            "Requirement already satisfied: numba!=0.49.0 in /usr/local/lib/python3.10/dist-packages (from pymatting->rembg) (0.58.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->rembg) (3.3)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->rembg) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->rembg) (2024.7.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->rembg) (1.6.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba!=0.49.0->pymatting->rembg) (0.41.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch->rembg) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch->rembg) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch->rembg) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch->rembg) (2024.7.4)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime->rembg) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime->rembg) (1.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: pyfonts in /usr/local/lib/python3.10/dist-packages (0.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from pyfonts) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyfonts) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyfonts) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyfonts) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyfonts) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyfonts) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyfonts) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyfonts) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyfonts) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyfonts) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->pyfonts) (1.16.0)\n",
            "Requirement already satisfied: gradio_image_annotation in /usr/local/lib/python3.10/dist-packages (0.2.3)\n",
            "Requirement already satisfied: gradio<5.0,>=4.29 in /usr/local/lib/python3.10/dist-packages (from gradio_image_annotation) (4.44.1)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (0.115.3)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (0.3.2)\n",
            "Requirement already satisfied: gradio-client==1.3.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (1.3.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (0.27.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (0.26.1)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (1.25.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (3.10.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (2.8.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (0.0.12)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (6.0.1)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (0.5.5)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (2.0.7)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (0.30.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio<5.0,>=4.29->gradio_image_annotation) (2023.6.0)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio<5.0,>=4.29->gradio_image_annotation) (11.0.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio<5.0,>=4.29->gradio_image_annotation) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio<5.0,>=4.29->gradio_image_annotation) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio<5.0,>=4.29->gradio_image_annotation) (1.2.2)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi<1.0->gradio<5.0,>=4.29->gradio_image_annotation) (0.41.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio<5.0,>=4.29->gradio_image_annotation) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio<5.0,>=4.29->gradio_image_annotation) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio<5.0,>=4.29->gradio_image_annotation) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio<5.0,>=4.29->gradio_image_annotation) (3.15.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio<5.0,>=4.29->gradio_image_annotation) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio<5.0,>=4.29->gradio_image_annotation) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio<5.0,>=4.29->gradio_image_annotation) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio<5.0,>=4.29->gradio_image_annotation) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio<5.0,>=4.29->gradio_image_annotation) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio<5.0,>=4.29->gradio_image_annotation) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio<5.0,>=4.29->gradio_image_annotation) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio<5.0,>=4.29->gradio_image_annotation) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio<5.0,>=4.29->gradio_image_annotation) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio<5.0,>=4.29->gradio_image_annotation) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio<5.0,>=4.29->gradio_image_annotation) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio<5.0,>=4.29->gradio_image_annotation) (2.20.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio<5.0,>=4.29->gradio_image_annotation) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio<5.0,>=4.29->gradio_image_annotation) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio<5.0,>=4.29->gradio_image_annotation) (13.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio<5.0,>=4.29->gradio_image_annotation) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<5.0,>=4.29->gradio_image_annotation) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<5.0,>=4.29->gradio_image_annotation) (2.16.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio<5.0,>=4.29->gradio_image_annotation) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio<5.0,>=4.29->gradio_image_annotation) (0.1.2)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.44.1)\n",
            "Collecting gradio\n",
            "  Using cached gradio-5.4.0-py3-none-any.whl (56.7 MB)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.115.3)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.2)\n",
            "Requirement already satisfied: gradio-client==1.3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.3.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.1)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.8.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.12)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.5.5)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.30.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (2023.6.0)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (11.0.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi<1.0->gradio) (0.41.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.15.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.20.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Requirement already satisfied: gradio_image_annotation in /usr/local/lib/python3.10/dist-packages (0.2.3)\n",
            "Requirement already satisfied: gradio<5.0,>=4.29 in /usr/local/lib/python3.10/dist-packages (from gradio_image_annotation) (4.44.1)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (0.115.3)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (0.3.2)\n",
            "Requirement already satisfied: gradio-client==1.3.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (1.3.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (0.27.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (0.26.1)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (1.25.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (3.10.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (2.8.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (0.0.12)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (6.0.1)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (0.5.5)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (2.0.7)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio<5.0,>=4.29->gradio_image_annotation) (0.30.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio<5.0,>=4.29->gradio_image_annotation) (2023.6.0)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio<5.0,>=4.29->gradio_image_annotation) (11.0.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio<5.0,>=4.29->gradio_image_annotation) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio<5.0,>=4.29->gradio_image_annotation) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio<5.0,>=4.29->gradio_image_annotation) (1.2.2)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi<1.0->gradio<5.0,>=4.29->gradio_image_annotation) (0.41.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio<5.0,>=4.29->gradio_image_annotation) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio<5.0,>=4.29->gradio_image_annotation) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio<5.0,>=4.29->gradio_image_annotation) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio<5.0,>=4.29->gradio_image_annotation) (3.15.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio<5.0,>=4.29->gradio_image_annotation) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio<5.0,>=4.29->gradio_image_annotation) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio<5.0,>=4.29->gradio_image_annotation) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio<5.0,>=4.29->gradio_image_annotation) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio<5.0,>=4.29->gradio_image_annotation) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio<5.0,>=4.29->gradio_image_annotation) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio<5.0,>=4.29->gradio_image_annotation) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio<5.0,>=4.29->gradio_image_annotation) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio<5.0,>=4.29->gradio_image_annotation) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio<5.0,>=4.29->gradio_image_annotation) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio<5.0,>=4.29->gradio_image_annotation) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio<5.0,>=4.29->gradio_image_annotation) (2.20.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio<5.0,>=4.29->gradio_image_annotation) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio<5.0,>=4.29->gradio_image_annotation) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio<5.0,>=4.29->gradio_image_annotation) (13.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio<5.0,>=4.29->gradio_image_annotation) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<5.0,>=4.29->gradio_image_annotation) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<5.0,>=4.29->gradio_image_annotation) (2.16.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio<5.0,>=4.29->gradio_image_annotation) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio<5.0,>=4.29->gradio_image_annotation) (0.1.2)\n",
            "\n",
            "INFO. Installed all libraries. RESTARTING runtime.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Import Required Global Packages\n",
        "\n",
        "# General Colab Packages\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "# General OS Packages\n",
        "import os\n",
        "import io\n",
        "import json\n",
        "import numpy as np\n",
        "import shutil\n",
        "import pandas as pd\n",
        "from os.path import splitext\n",
        "from typing import List, Sequence\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "import numpy as np\n",
        "import base64\n",
        "import datetime\n",
        "import time\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "# Google Cloud / API Imports\n",
        "from google.cloud import storage\n",
        "from google.cloud import resourcemanager_v3\n",
        "from google.api_core.exceptions import NotFound\n",
        "\n",
        "# Vertex AI Imports\n",
        "import vertexai\n",
        "import requests\n",
        "from vertexai.generative_models import (\n",
        "    Content,\n",
        "    FunctionDeclaration,\n",
        "    GenerationConfig,\n",
        "    GenerativeModel,\n",
        "    Part,\n",
        "    Tool,\n",
        ")\n",
        "\n",
        "# @title Import Required Global Packages\n",
        "\n",
        "# General Colab Packages\n",
        "from google.colab import drive\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "n85GQJ06unpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Initializate Project configuration\n",
        "\n",
        "# Google Cloud Project\n",
        "PROJECT_ID = \"genai-e2e-demos\" # @param {type:\"string\"}\n",
        "PROJECT_LOCATION = \"us-central1\" # @param {type:\"string\"}\n",
        "GCS_LOCATION = \"US\" # @param {type:\"string\"}\n",
        "\n",
        "# Create a client\n",
        "client = resourcemanager_v3.ProjectsClient()\n",
        "# Get the project ID from the project name\n",
        "project_name = f\"projects/{PROJECT_ID}\"  # Change this to your project ID\n",
        "# Make the request\n",
        "response = client.get_project(name=project_name)\n",
        "\n",
        "# Retrieve PROJECT_NUMBER value\n",
        "PROJECT_NUMBER = client.get_project(name=project_name).name.split(\"/\")[-1]\n",
        "\n",
        "print(f\"Connecting to Google Cloud Project ID: {PROJECT_ID} with Project Number: {PROJECT_NUMBER} in location: {PROJECT_LOCATION}\")"
      ],
      "metadata": {
        "id": "ELafaMOXu8Z0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730341434485,
          "user_tz": -480,
          "elapsed": 2762,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "e7040ef4-eb02-471b-9104-819590961d3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Connecting to Google Cloud Project ID: genai-e2e-demos with Project Number: 554686566379 in location: us-central1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section - Code (Global Pre-req - Imports / Initialization)"
      ],
      "metadata": {
        "id": "NBmu23BL53H9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Initializate Vertex AI Client\n",
        "\n",
        "# Initialization - ADC Not necessary since we already logged into Colab\n",
        "\n",
        "# credentials = service_account.Credentials.from_service_account_file(SVC_KEY_PATH)\n",
        "# OR\n",
        "# !gcloud auth application-default login\n",
        "# !gcloud auth application-default set-quota-project $PROJECT_ID\n",
        "\n",
        "# Initialization - Vertex AI\n",
        "vertexai.init(project=PROJECT_ID, location=PROJECT_LOCATION)"
      ],
      "metadata": {
        "id": "re5FLjZu5AIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section - Utility Functions"
      ],
      "metadata": {
        "id": "XdYklEg473Ne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Utility - Assorted General GCS Related\n",
        "\n",
        "def list_files_in_gcs_bucket(bucket_name, project_id):\n",
        "    \"\"\"Lists all the blobs in the bucket.\"\"\"\n",
        "    storage_client = storage.Client(project=project_id)\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blobs = bucket.list_blobs()  # Get all blobs\n",
        "    return [blob.name for blob in blobs]  # Extract filenames\n",
        "\n",
        "def list_files_in_gcs_bucket_folder(bucket_name, folder, project_id):\n",
        "    \"\"\"Lists all the files within a specified folder in the bucket.\"\"\"\n",
        "    storage_client = storage.Client(project=project_id)\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "\n",
        "    # Use the prefix parameter to filter blobs within the folder\n",
        "    blobs = bucket.list_blobs(prefix=folder)\n",
        "\n",
        "    return [blob.name for blob in blobs]\n",
        "\n",
        "def download_to_local_folder_from_gcs_bucket(bucket_name, file_name, local_folder_path, project_id):\n",
        "  \"\"\"Downloads a blob from GCS and saves it locally\"\"\"\n",
        "  storage_client = storage.Client(project=project_id)\n",
        "\n",
        "  bucket = storage_client.bucket(bucket_name)\n",
        "  blob = bucket.blob(file_name)\n",
        "\n",
        "  try:\n",
        "      # Check if blob exists before downloading\n",
        "      if blob.exists():\n",
        "        # Create destination directory if it doesn't exist\n",
        "          # Extract the GCS folder structure from the file name\n",
        "          gcs_folder_path = os.path.dirname(file_name)\n",
        "\n",
        "          # Combine the local folder path with the GCS folder structure\n",
        "          full_local_path = os.path.join(local_folder_path, gcs_folder_path)\n",
        "\n",
        "          # Create the full local directory structure if it doesn't exist\n",
        "          os.makedirs(full_local_path, exist_ok=True)\n",
        "\n",
        "          dst_file_path = os.path.join(full_local_path, os.path.basename(file_name))\n",
        "\n",
        "          blob.download_to_filename(dst_file_path)\n",
        "          print(f\"Downloaded {file_name} to {full_local_path}\")\n",
        "      else:\n",
        "          print(f\"Blob {file_name} does not exist in bucket {bucket_name}\")\n",
        "  except Exception as e:\n",
        "      print(f\"An error occurred: {e}\")\n",
        "\n",
        "def download_to_local_folder_from_gcs_folder(bucket_name, file_name, local_folder_path, project_id):\n",
        "\n",
        "  \"\"\"Downloads a blob from GCS and saves it locally\"\"\"\n",
        "  storage_client = storage.Client(project=project_id)\n",
        "\n",
        "  bucket = storage_client.bucket(bucket_name)\n",
        "  blob = bucket.blob(file_name)\n",
        "\n",
        "  try:\n",
        "      # Check if blob exists before downloading\n",
        "      if blob.exists():\n",
        "          # Create destination directory if it doesn't exist\n",
        "          destination_directory = os.path.dirname(local_folder_path)\n",
        "          os.makedirs(destination_directory, exist_ok=True)\n",
        "\n",
        "          dst_file_path = os.path.join(local_folder_path, os.path.basename(file_name))\n",
        "          blob.download_to_filename(dst_file_path)\n",
        "          print(f\"Downloaded {file_name} to {local_folder_path}\")\n",
        "      else:\n",
        "          print(f\"Blob {file_name} does not exist in bucket {bucket_name}\")\n",
        "  except Exception as e:\n",
        "      print(f\"An error occurred: {e}\")\n",
        "\n",
        "def copy_file_to_gcs(localfilepath, gcs_bucket_name, gcs_folder, gcs_filename, project_id):\n",
        "    \"\"\"Copies a local file to Google Cloud Storage.\"\"\"\n",
        "\n",
        "    try:\n",
        "        # Check if the file exists\n",
        "        if not os.path.exists(localfilepath):\n",
        "            raise FileNotFoundError(f\"File not found: {localfilepath}\")\n",
        "\n",
        "        # Upload to Google Cloud Storage\n",
        "        storage_client = storage.Client(project=project_id)\n",
        "        bucket = storage_client.bucket(gcs_bucket_name)\n",
        "\n",
        "        # Create the bucket if it doesn't exist\n",
        "        if not bucket.exists():\n",
        "            bucket = storage_client.create_bucket(gcs_bucket_name)\n",
        "\n",
        "        blob_name = os.path.join(gcs_folder, gcs_filename)\n",
        "        blob = bucket.blob(blob_name)\n",
        "\n",
        "        # Upload the local file, overwriting if it exists\n",
        "        blob.upload_from_filename(localfilepath)\n",
        "\n",
        "        print(\n",
        "            f\"File {localfilepath} uploaded to gs://{gcs_bucket_name}/{blob_name}\"\n",
        "        )\n",
        "\n",
        "    except (FileNotFoundError, ValueError, Exception) as e:  # Use PyPDF2.utils.PdfReadError\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "def delete_bucket_and_contents(bucket_name, project_id):\n",
        "    \"\"\"Deletes a GCS bucket and all its contents.\"\"\"\n",
        "\n",
        "    storage_client = storage.Client(project=project_id)\n",
        "\n",
        "    try:\n",
        "        # Get the bucket object\n",
        "        bucket = storage_client.get_bucket(bucket_name)\n",
        "\n",
        "        # Delete all blobs (objects) in the bucket\n",
        "        blobs = bucket.list_blobs()\n",
        "        for blob in blobs:\n",
        "            blob.delete()\n",
        "        print(f\"Deleted all objects in bucket {bucket_name}\")\n",
        "\n",
        "        # Delete the bucket itself\n",
        "        bucket.delete()\n",
        "        print(f\"Deleted bucket {bucket_name}\")\n",
        "\n",
        "    except NotFound:\n",
        "        print(f\"Bucket {bucket_name} not found, ignoring.\")\n",
        "\n",
        "def delete_bucket_contents(bucket_name, project_id):\n",
        "    \"\"\"Deletes all contents in GCS bucket.\"\"\"\n",
        "\n",
        "    storage_client = storage.Client(project=project_id)\n",
        "\n",
        "    try:\n",
        "        # Get the bucket object\n",
        "        bucket = storage_client.get_bucket(bucket_name)\n",
        "\n",
        "        # Delete all blobs (objects) in the bucket\n",
        "        blobs = bucket.list_blobs()\n",
        "        for blob in blobs:\n",
        "            blob.delete()\n",
        "        print(f\"Deleted all objects in bucket {bucket_name}\")\n",
        "\n",
        "    except NotFound:\n",
        "        print(f\"Bucket {bucket_name} not found, ignoring.\")\n",
        "\n",
        "def create_bucket_if_not_exists(bucket_name, project_id, location=GCS_LOCATION):\n",
        "    \"\"\"Creates a GCS bucket if it doesn't already exist. \"\"\"\n",
        "\n",
        "    storage_client = storage.Client(project=project_id)\n",
        "\n",
        "    try:\n",
        "        bucket = storage_client.get_bucket(bucket_name)\n",
        "        print(f\"Bucket {bucket_name} already exists.\")  # Bucket found\n",
        "    except:  # Bucket not found, so create it\n",
        "        bucket = storage_client.bucket(bucket_name)\n",
        "        bucket.storage_class = \"STANDARD\"\n",
        "        new_bucket = storage_client.create_bucket(bucket, location=location)\n",
        "        print(f\"Created bucket {new_bucket.name} in {new_bucket.location}.\")"
      ],
      "metadata": {
        "id": "GfJJzMyN8FPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Utility - Folder / File Mgmt. Functions\n",
        "\n",
        "def list_files_in_folder(folder_path, folder_name=''):\n",
        "  file_list = []\n",
        "  for item in os.listdir(folder_path):\n",
        "      item_path = os.path.join(folder_path, item)\n",
        "      if os.path.isfile(item_path):\n",
        "          file_list.append(os.path.join(folder_name, item))\n",
        "      elif os.path.isdir(item_path):\n",
        "          file_list.extend(list_files_in_folder(item_path, os.path.join(folder_name, item)))\n",
        "  return file_list\n",
        "\n",
        "def download_to_computer(folder_path, file_name):\n",
        "  file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "  if os.path.exists(file_path):  # Check if the file exists\n",
        "      files.download(file_path)  # Download to the local computer\n",
        "      print(f\"Downloaded '{file_name}'\")\n",
        "  else:\n",
        "      print(f\"File not found: '{file_name}'\")\n",
        "\n",
        "def download_to_local_folder(src_folder_path, file_name, local_folder_path):\n",
        "  src_file_path = os.path.join(src_folder_path, file_name)\n",
        "  dst_file_path = os.path.join(local_folder_path, file_name)\n",
        "\n",
        "  if os.path.exists(src_file_path):  # Check if the file exists\n",
        "\n",
        "      # Copy the file from Google Drive\n",
        "      shutil.copy(src_file_path, dst_file_path)\n",
        "      print(f\"Copied '{file_name}' to {dst_file_path}\")\n",
        "  else:\n",
        "      print(f\"File not found: '{file_name}'\")\n",
        "\n",
        "def copy_with_subfolders(src, dst):\n",
        "\n",
        "  if not os.path.exists(dst):\n",
        "    os.makedirs(dst)  # Create the destination directory if it doesn't exist\n",
        "\n",
        "  for item in os.listdir(src):\n",
        "    src_element = os.path.join(src, item)\n",
        "    dst_element = os.path.join(dst, item)\n",
        "    if os.path.isdir(src_element):\n",
        "      shutil.copytree(src_element, dst_element)\n",
        "  # Recursively copy subdirectories\n",
        "    else:\n",
        "      shutil.copy2(src_element, dst_element)  # Copy files\n",
        "\n",
        "def delete_all_files(directory):\n",
        "\n",
        "  for filename in os.listdir(directory):\n",
        "    file_path = os.path.join(directory, filename)\n",
        "    try:\n",
        "      if os.path.isfile(file_path):\n",
        "        os.remove(file_path)\n",
        "\n",
        "        print(f\"Deleted: {file_path}\")\n",
        "    except Exception as e:\n",
        "      print(f\"Error deleting {file_path}: {e}\")\n",
        "\n",
        "def get_filenames_in_folder(path):\n",
        "\n",
        "  filenames = []\n",
        "  for item in os.listdir(path):\n",
        "    item_path = os.path.join(path, item)\n",
        "    if os.path.isfile(item_path):\n",
        "      filenames.append(item)\n",
        "  return filenames\n",
        "\n",
        "def get_filepath_in_folder_nested(path):\n",
        "  filenames = []\n",
        "  for item in os.listdir(path):\n",
        "    item_path = os.path.join(path, item)\n",
        "    if os.path.isfile(item_path):\n",
        "      filenames.append(item_path)  # Append the full path\n",
        "    elif os.path.isdir(item_path):\n",
        "      filenames.extend(get_filepath_in_folder_nested(item_path))  # Recursive call\n",
        "  return filenames\n",
        "\n",
        "def find_files_with_prefix(directory, prefix):\n",
        "  matching_files = []\n",
        "  for root, _, files in os.walk(directory):\n",
        "    for file in files:\n",
        "      if file.startswith(prefix):\n",
        "        matching_files.append(os.path.join(root, file))\n",
        "  return matching_files\n",
        "\n",
        "def create_file_map(folder_path, extension, prefix):\n",
        "  file_map = {}\n",
        "  for filename in os.listdir(folder_path):\n",
        "    if os.path.isfile(os.path.join(folder_path, filename)):\n",
        "      base_name, file_extension = os.path.splitext(filename)\n",
        "\n",
        "      if file_extension.lower() == extension.lower():  # Case-insensitive comparison\n",
        "        absolute_path = os.path.abspath(os.path.join(folder_path, filename))\n",
        "        file_map[base_name.removeprefix(prefix)] = absolute_path\n",
        "\n",
        "  return file_map"
      ],
      "metadata": {
        "id": "ANbvA-e1C4Sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Utility - Assorted JSON Handling for Gradio\n",
        "\n",
        "def json_to_html_table(json_data):\n",
        "    try:\n",
        "        data_dict = json.loads(json_data)\n",
        "    except json.JSONDecodeError:\n",
        "        return \"<p>Invalid JSON format.</p>\"\n",
        "\n",
        "    html_table = \"\"\"\n",
        "    <table border=\"1\">\n",
        "        <tr>\n",
        "            <th>Attribute</th>\n",
        "            <th>Value</th>\n",
        "        </tr>\n",
        "    \"\"\"\n",
        "\n",
        "    for key, value in data_dict.items():\n",
        "        html_table += f\"<tr><td>{key}</td><td>{value}</td></tr>\"\n",
        "\n",
        "    html_table += \"</table>\"\n",
        "    return html_table"
      ],
      "metadata": {
        "id": "s5A7AzqoWDM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Utility - Imagen3 & Gemini Model Invocations\n",
        "\n",
        "import vertexai\n",
        "from vertexai.preview.vision_models import ImageGenerationModel\n",
        "\n",
        "def generate_imagen_outputs(prompt, number_of_images, aspect_ratio, model=\"imagen-3.0-generate-001\"):\n",
        "  print(f\"Input - No. of Images : {number_of_images}, Aspect Ratio {aspect_ratio}, Model {model}, Prompt - \\n {prompt}\")\n",
        "  generation_model = ImageGenerationModel.from_pretrained(model)\n",
        "  image_list = generation_model.generate_images(\n",
        "      prompt=prompt,\n",
        "      number_of_images=number_of_images,\n",
        "      aspect_ratio=aspect_ratio,\n",
        "  )\n",
        "  print(f\"Generated {len(image_list.images)} images for prompt with model {model}\")\n",
        "  return image_list.images\n",
        "\n",
        "# Usage\n",
        "# import io\n",
        "# import base64\n",
        "# from PIL import Image\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# prompt_x = f\"\"\"\n",
        "#   \"Subject: a young Indonesian woman\"\n",
        "#   \"Age: 20-30 years old\"\n",
        "#   \"Clothing: Modern stylish clothing in red / yellow\"\n",
        "#   \"Theme: Joyfully looking at her phone\"\n",
        "#   \"Environment Settings: white bacjground\"\n",
        "#   \"Photography Setting: studio lighting, DLSR\"\n",
        "# \"\"\"\n",
        "\n",
        "# image_list = generate_imagen_outputs(prompt_x, 1, \"4:3\")\n",
        "\n",
        "# processed_images = []\n",
        "# for generated_image in image_list:\n",
        "#     print(f\"In generated_image\")\n",
        "#     generated_image_data = base64.b64decode(generated_image._as_base64_string())\n",
        "#     pil_image = Image.open(io.BytesIO(generated_image_data))\n",
        "\n",
        "#     # Display the image\n",
        "#     pil_image.show()\n",
        "\n",
        "#     # Display with matplotlib\n",
        "#     plt.imshow(pil_image)\n",
        "#     plt.axis('off')  # Hide axes\n",
        "#     plt.show()\n",
        "\n",
        "def invoke_gemini_multimodal_model_with_files(model: GenerativeModel, contents: list[Content]):\n",
        "  response = model.generate_content(contents)\n",
        "  return (response)\n",
        "\n",
        "def invoke_gemini_for_text(prompt, model_input=\"gemini-1.5-pro-001\"):\n",
        "  model = GenerativeModel(model_input)\n",
        "  response = model.generate_content(prompt)\n",
        "  return response.text"
      ],
      "metadata": {
        "id": "Gjr95CxNGNRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section - Demo Configuration & Initialization"
      ],
      "metadata": {
        "id": "9Kj952xKCRcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Demo Notebook Configuration Step 1A - Create local folders for input and output, initialize asset library\n",
        "\n",
        "LOCAL_INPUT_DIR = \"/content/demo/input\"\n",
        "LOCAL_INPUT_DIR_ARTEFACTS = f\"{LOCAL_INPUT_DIR}/Artefacts\"\n",
        "LOCAL_INPUT_DIR_ACTOR = f\"{LOCAL_INPUT_DIR_ARTEFACTS}/Actors\"\n",
        "LOCAL_INPUT_DIR_BG = f\"{LOCAL_INPUT_DIR_ARTEFACTS}/Background\"\n",
        "LOCAL_INPUT_DIR_LOGO = f\"{LOCAL_INPUT_DIR_ARTEFACTS}/Logo\"\n",
        "LOCAL_INPUT_DIR_GRAPHICS = f\"{LOCAL_INPUT_DIR_ARTEFACTS}/Graphics\"\n",
        "LOCAL_INPUT_DIR_CONFIG = f\"{LOCAL_INPUT_DIR_ARTEFACTS}/Config\"\n",
        "\n",
        "LOCAL_TEMP_DIR = \"/content/demo/temp\"\n",
        "\n",
        "LOCAL_OUTPUT_DIR = \"/content/demo/output\"\n",
        "LOCAL_OUTPUT_DIR_ACTOR = \"/content/demo/output/Actors_Processed\"\n",
        "LOCAL_OUTPUT_DIR_BG = \"/content/demo/output/Background_Processed\"\n",
        "LOCAL_OUTPUT_DIR_BANNER = \"/content/demo/output/Banner_Processed\"\n",
        "\n",
        "# Demo Configuration Attributes\n",
        "democonfig_artefacts_required = [\n",
        "    \"Artefacts/Config/config.json\"\n",
        "]\n",
        "\n",
        "# Delete existing contents and reset\n",
        "if os.path.exists(LOCAL_INPUT_DIR):\n",
        "    shutil.rmtree(LOCAL_INPUT_DIR)  # Delete the existing directory and its contents\n",
        "\n",
        "if os.path.exists(LOCAL_TEMP_DIR):\n",
        "    shutil.rmtree(LOCAL_TEMP_DIR)  # Delete the existing directory and its contents\n",
        "\n",
        "if os.path.exists(LOCAL_OUTPUT_DIR):\n",
        "    shutil.rmtree(LOCAL_OUTPUT_DIR)  # Delete the existing directory and its contents\n",
        "\n",
        "os.makedirs(LOCAL_INPUT_DIR)  # Recreate the directory\n",
        "os.makedirs(LOCAL_INPUT_DIR_ACTOR)  # Recreate the directory\n",
        "os.makedirs(LOCAL_INPUT_DIR_BG)  # Recreate the directory\n",
        "os.makedirs(LOCAL_INPUT_DIR_LOGO)  # Recreate the directory\n",
        "os.makedirs(LOCAL_INPUT_DIR_GRAPHICS)  # Recreate the directory\n",
        "os.makedirs(LOCAL_INPUT_DIR_CONFIG)  # Recreate the directory\n",
        "\n",
        "os.makedirs(LOCAL_TEMP_DIR)  # Recreate the directory\n",
        "\n",
        "os.makedirs(LOCAL_OUTPUT_DIR)  # Recreate the directory\n",
        "# os.makedirs(LOCAL_OUTPUT_DIR_ACTOR)  # Recreate the directory\n",
        "# os.makedirs(LOCAL_OUTPUT_DIR_BG)  # Recreate the directory\n",
        "os.makedirs(LOCAL_OUTPUT_DIR_BANNER)  # Recreate the directory\n",
        "\n",
        "# # Configure initialize path for input and temp outputs\n",
        "# BANNER_INPUT_DRIVE_SRC = 'Colab Notebooks/IOH-BannerGen/Artefacts' # @param {type:\"string\"}\n",
        "# banner_input_drive_path = os.path.join(DRIVE_HOME, BANNER_INPUT_DRIVE_SRC)\n",
        "\n",
        "# # Copy files from Google Drive to the local directory\n",
        "# copy_with_subfolders(banner_input_drive_path, LOCAL_INPUT_DIR)\n",
        "\n",
        "# # Demo GCS Defaults\n",
        "demo_input_gcs_bucket_root =\"telecom_demo_artefacts_bannergen_input\"\n",
        "demo_input_gcs_bucket = f\"{PROJECT_NUMBER}_{demo_input_gcs_bucket_root}\"\n",
        "demo_input_gcs_bucket_config = f\"{PROJECT_NUMBER}_{demo_input_gcs_bucket}/Artefacts/Config\"\n",
        "print (f\"Loading configuration from gs://{demo_input_gcs_bucket}\")\n",
        "\n",
        "demo_runtime_gcs_bucket_root =\"telecom_demo_artefacts_bannergen_runtime\"\n",
        "demo_runtime_gcs_bucket = f\"{PROJECT_NUMBER}_{demo_runtime_gcs_bucket_root}\"\n",
        "demo_runtime_gcs_bucket_temp = f\"{PROJECT_NUMBER}_{demo_runtime_gcs_bucket_root}_temp\"\n",
        "demo_runtime_gcs_bucket_output = f\"{PROJECT_NUMBER}_{demo_runtime_gcs_bucket_root}_output\"\n",
        "\n",
        "# Clean up GCS Buckets\n",
        "create_bucket_if_not_exists(demo_input_gcs_bucket, PROJECT_ID)\n",
        "\n",
        "print(f\"\\nRebuilding notebook GCP bucket(s) holding temp files from scratch.\")\n",
        "create_bucket_if_not_exists(demo_runtime_gcs_bucket, PROJECT_ID)\n",
        "delete_bucket_contents(demo_runtime_gcs_bucket, PROJECT_ID)\n",
        "\n",
        "# Get list of files in the initialize location\n",
        "existing_files = list_files_in_gcs_bucket(f\"{demo_input_gcs_bucket}\", PROJECT_ID)\n",
        "\n",
        "# Categorize files\n",
        "required_and_found = [mandatoryfile for mandatoryfile in democonfig_artefacts_required if mandatoryfile in existing_files]\n",
        "required_but_not_found = [mandatoryfile for mandatoryfile in democonfig_artefacts_required if mandatoryfile not in existing_files]\n",
        "\n",
        "# Print summaries\n",
        "print(f\"\\nRequired demo config files found ({len(required_and_found)}):\")\n",
        "for file in required_and_found:\n",
        "    print(f\"- {file}\")\n",
        "\n",
        "print(f\"\\nRequired files demo config files not found ({len(required_but_not_found)}):\")\n",
        "for file in required_but_not_found:\n",
        "    print(f\"- {file}\")\n",
        "\n",
        "# Check initialization status and raise exception if needed\n",
        "if required_but_not_found:\n",
        "    missing_files_str = \", \".join(required_but_not_found)\n",
        "    print(\"\\nDemo initialization status: Failed\")\n",
        "    raise FileNotFoundError(f\"Mandatory config files not found in {democonfig_artefacts_required}\")\n",
        "else:\n",
        "    print(f\"\\nDownloading Demo Artefacts from GCS bucket - {democonfig_artefacts_required}\")\n",
        "    # Download each required demo artefacts files from central location\n",
        "    for file_name in existing_files:\n",
        "      download_to_local_folder_from_gcs_bucket(demo_input_gcs_bucket, file_name, LOCAL_INPUT_DIR, PROJECT_ID)\n",
        "\n",
        "    # Move relevant folders to output directory\n",
        "    shutil.move(f\"{LOCAL_INPUT_DIR_ARTEFACTS}/Actors_Processed\", LOCAL_OUTPUT_DIR)\n",
        "    shutil.move(f\"{LOCAL_INPUT_DIR_ARTEFACTS}/Background_Processed\", LOCAL_OUTPUT_DIR)\n",
        "\n",
        "    print(\"\\nDemo initialization status: Successful\")"
      ],
      "metadata": {
        "id": "kV8yyrCyCpU4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730341589702,
          "user_tz": -480,
          "elapsed": 154889,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "088cc415-4e8a-4f77-eb42-d3d7952c7d74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading configuration from gs://554686566379_telecom_demo_artefacts_bannergen_input\n",
            "Bucket 554686566379_telecom_demo_artefacts_bannergen_input already exists.\n",
            "\n",
            "Rebuilding notebook GCP bucket(s) holding temp files from scratch.\n",
            "Bucket 554686566379_telecom_demo_artefacts_bannergen_runtime already exists.\n",
            "Deleted all objects in bucket 554686566379_telecom_demo_artefacts_bannergen_runtime\n",
            "\n",
            "Required demo config files found (1):\n",
            "- Artefacts/Config/config.json\n",
            "\n",
            "Required files demo config files not found (0):\n",
            "\n",
            "Downloading Demo Artefacts from GCS bucket - ['Artefacts/Config/config.json']\n",
            "Downloaded Artefacts/Actors/Old_Woman_Individual/Old_Woman_Individual_1.png to /content/demo/input/Artefacts/Actors/Old_Woman_Individual\n",
            "Downloaded Artefacts/Actors/Old_Woman_Individual/Old_Woman_Individual_2.png to /content/demo/input/Artefacts/Actors/Old_Woman_Individual\n",
            "Downloaded Artefacts/Actors/Old_Woman_Individual/Old_Woman_Individual_3.png to /content/demo/input/Artefacts/Actors/Old_Woman_Individual\n",
            "Downloaded Artefacts/Actors/Young_Digital_Duo/Young_Digital_Duo_1.png to /content/demo/input/Artefacts/Actors/Young_Digital_Duo\n",
            "Downloaded Artefacts/Actors/Young_Digital_Duo/Young_Digital_Duo_2.png to /content/demo/input/Artefacts/Actors/Young_Digital_Duo\n",
            "Downloaded Artefacts/Actors/Young_Digital_Duo/Young_Digital_Duo_3.png to /content/demo/input/Artefacts/Actors/Young_Digital_Duo\n",
            "Downloaded Artefacts/Actors/Young_Gamers_Group/Young_Gamers_Group_1.png to /content/demo/input/Artefacts/Actors/Young_Gamers_Group\n",
            "Downloaded Artefacts/Actors/Young_Gamers_Group/Young_Gamers_Group_2.png to /content/demo/input/Artefacts/Actors/Young_Gamers_Group\n",
            "Downloaded Artefacts/Actors/Young_Gamers_Group/Young_Gamers_Group_3.png to /content/demo/input/Artefacts/Actors/Young_Gamers_Group\n",
            "Downloaded Artefacts/Actors/Young_Hijab_Group/Young_Hijab_Group_1.png to /content/demo/input/Artefacts/Actors/Young_Hijab_Group\n",
            "Downloaded Artefacts/Actors/Young_Hijab_Group/Young_Hijab_Group_2.png to /content/demo/input/Artefacts/Actors/Young_Hijab_Group\n",
            "Downloaded Artefacts/Actors/Young_Hijab_Group/Young_Hijab_Group_3.png to /content/demo/input/Artefacts/Actors/Young_Hijab_Group\n",
            "Downloaded Artefacts/Actors_Processed/Mask_Old_Woman_Individual_1.png to /content/demo/input/Artefacts/Actors_Processed\n",
            "Downloaded Artefacts/Actors_Processed/Mask_Old_Woman_Individual_2.png to /content/demo/input/Artefacts/Actors_Processed\n",
            "Downloaded Artefacts/Actors_Processed/Mask_Old_Woman_Individual_3.png to /content/demo/input/Artefacts/Actors_Processed\n",
            "Downloaded Artefacts/Actors_Processed/Mask_Young_Digital_Duo_1.png to /content/demo/input/Artefacts/Actors_Processed\n",
            "Downloaded Artefacts/Actors_Processed/Mask_Young_Digital_Duo_2.png to /content/demo/input/Artefacts/Actors_Processed\n",
            "Downloaded Artefacts/Actors_Processed/Mask_Young_Digital_Duo_3.png to /content/demo/input/Artefacts/Actors_Processed\n",
            "Downloaded Artefacts/Actors_Processed/Mask_Young_Gamers_Group_1.png to /content/demo/input/Artefacts/Actors_Processed\n",
            "Downloaded Artefacts/Actors_Processed/Mask_Young_Gamers_Group_2.png to /content/demo/input/Artefacts/Actors_Processed\n",
            "Downloaded Artefacts/Actors_Processed/Mask_Young_Gamers_Group_3.png to /content/demo/input/Artefacts/Actors_Processed\n",
            "Downloaded Artefacts/Actors_Processed/Mask_Young_Hijab_Group_1.png to /content/demo/input/Artefacts/Actors_Processed\n",
            "Downloaded Artefacts/Actors_Processed/Mask_Young_Hijab_Group_2.png to /content/demo/input/Artefacts/Actors_Processed\n",
            "Downloaded Artefacts/Actors_Processed/Mask_Young_Hijab_Group_3.png to /content/demo/input/Artefacts/Actors_Processed\n",
            "Downloaded Artefacts/Actors_Processed/NoBg_Old_Woman_Individual_1.png to /content/demo/input/Artefacts/Actors_Processed\n",
            "Downloaded Artefacts/Actors_Processed/NoBg_Old_Woman_Individual_2.png to /content/demo/input/Artefacts/Actors_Processed\n",
            "Downloaded Artefacts/Actors_Processed/NoBg_Old_Woman_Individual_3.png to /content/demo/input/Artefacts/Actors_Processed\n",
            "Downloaded Artefacts/Actors_Processed/NoBg_Young_Digital_Duo_1.png to /content/demo/input/Artefacts/Actors_Processed\n",
            "Downloaded Artefacts/Actors_Processed/NoBg_Young_Digital_Duo_2.png to /content/demo/input/Artefacts/Actors_Processed\n",
            "Downloaded Artefacts/Actors_Processed/NoBg_Young_Digital_Duo_3.png to /content/demo/input/Artefacts/Actors_Processed\n",
            "Downloaded Artefacts/Actors_Processed/NoBg_Young_Gamers_Group_1.png to /content/demo/input/Artefacts/Actors_Processed\n",
            "Downloaded Artefacts/Actors_Processed/NoBg_Young_Gamers_Group_2.png to /content/demo/input/Artefacts/Actors_Processed\n",
            "Downloaded Artefacts/Actors_Processed/NoBg_Young_Gamers_Group_3.png to /content/demo/input/Artefacts/Actors_Processed\n",
            "Downloaded Artefacts/Actors_Processed/NoBg_Young_Hijab_Group_1.png to /content/demo/input/Artefacts/Actors_Processed\n",
            "Downloaded Artefacts/Actors_Processed/NoBg_Young_Hijab_Group_2.png to /content/demo/input/Artefacts/Actors_Processed\n",
            "Downloaded Artefacts/Actors_Processed/NoBg_Young_Hijab_Group_3.png to /content/demo/input/Artefacts/Actors_Processed\n",
            "Downloaded Artefacts/Background/Template1.png to /content/demo/input/Artefacts/Background\n",
            "Downloaded Artefacts/Background/Template2.png to /content/demo/input/Artefacts/Background\n",
            "Downloaded Artefacts/Background/Template3.png to /content/demo/input/Artefacts/Background\n",
            "Downloaded Artefacts/Background_Processed/Grid_Template1.png to /content/demo/input/Artefacts/Background_Processed\n",
            "Downloaded Artefacts/Background_Processed/Grid_Template2.png to /content/demo/input/Artefacts/Background_Processed\n",
            "Downloaded Artefacts/Background_Processed/Grid_Template3.png to /content/demo/input/Artefacts/Background_Processed\n",
            "Downloaded Artefacts/Config/config.json to /content/demo/input/Artefacts/Config\n",
            "Downloaded Artefacts/Graphics/50GraphicH1.png to /content/demo/input/Artefacts/Graphics\n",
            "Downloaded Artefacts/Graphics/50GraphicH2.png to /content/demo/input/Artefacts/Graphics\n",
            "Downloaded Artefacts/Graphics/50GraphicV.png to /content/demo/input/Artefacts/Graphics\n",
            "Downloaded Artefacts/Graphics/Graphics1.png to /content/demo/input/Artefacts/Graphics\n",
            "Downloaded Artefacts/Graphics/Graphics2.png to /content/demo/input/Artefacts/Graphics\n",
            "Downloaded Artefacts/Graphics/Graphics3.png to /content/demo/input/Artefacts/Graphics\n",
            "Downloaded Artefacts/Graphics/Graphics4.png to /content/demo/input/Artefacts/Graphics\n",
            "Downloaded Artefacts/Logo/ctellogo.png to /content/demo/input/Artefacts/Logo\n",
            "Downloaded Artefacts/Logo/im3logo.png to /content/demo/input/Artefacts/Logo\n",
            "\n",
            "Demo initialization status: Successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Demo Notebook Configuration Step 1B - Reinitialize firebase, instance banner-gen-app should be pre-created\n",
        "\n",
        "flag_reinitialize_firebase = False #@param {type:\"boolean\"}\n",
        "\n",
        "from google.cloud import firestore\n",
        "\n",
        "FIRESTORE_INSTANCE_ID = \"banner-gen-app\"\n",
        "\n",
        "# Initialize Firestore Client (replace with your project ID and database ID)\n",
        "db = firestore.Client(project=PROJECT_ID, database=FIRESTORE_INSTANCE_ID)\n",
        "\n",
        "# Get a reference to the collection\n",
        "collection_visuals_segment_clusters = db.collection('visuals_segment_clusters')\n",
        "\n",
        "def init_visual_segment():\n",
        "  # Path to config.json file\n",
        "  config_file_path = LOCAL_INPUT_DIR_CONFIG + \"/config.json\"\n",
        "\n",
        "  try:\n",
        "    with open(config_file_path, 'r') as f:\n",
        "      config_data = json.load(f)\n",
        "\n",
        "    # Extract the visuals_segment_clusters array\n",
        "    visual_segments = config_data.get('visuals_segment_clusters', [])\n",
        "\n",
        "    # Get a reference to the collection\n",
        "    collection_ref = db.collection('visuals_segment_clusters')\n",
        "\n",
        "    # Add each visual segment to the collection\n",
        "    for segment in visual_segments:\n",
        "      # Use the 'visualsegment' value as the document ID\n",
        "      doc_ref = collection_ref.document(segment['visualsegment'])\n",
        "      doc_ref.set(segment)\n",
        "\n",
        "    print(\"Visual segments configuration added to Firestore successfully!\")\n",
        "\n",
        "  except FileNotFoundError:\n",
        "    print(f\"Error: Config file not found at {config_file_path}\")\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "\n",
        "def init_banner_template():\n",
        "  # Path to config.json file\n",
        "  config_file_path = LOCAL_INPUT_DIR_CONFIG + \"/config.json\"\n",
        "\n",
        "  try:\n",
        "    with open(config_file_path, 'r') as f:\n",
        "      config_data = json.load(f)\n",
        "\n",
        "    # Extract the banner_template array\n",
        "    banner_template = config_data.get('banner_template', [])\n",
        "\n",
        "    # Get a reference to the collection\n",
        "    collection_ref = db.collection('banner_template')\n",
        "\n",
        "    # Add each visual segment to the collection\n",
        "    for banner in banner_template:\n",
        "      # Use the 'bannertemplate' value as the document ID\n",
        "      doc_ref = collection_ref.document(banner['bannertemplate'])\n",
        "      doc_ref.set(banner)\n",
        "\n",
        "    print(\"Banner template configuration added to Firestore successfully!\")\n",
        "\n",
        "  except FileNotFoundError:\n",
        "    print(f\"Error: Config file not found at {config_file_path}\")\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Check if the collection exists\n",
        "if collection_visuals_segment_clusters.get():\n",
        "  if(flag_reinitialize_firebase):\n",
        "    print(\"Collection visuals_segment_clusters exists. Deleting...\")\n",
        "\n",
        "    # Delete all documents in the collection\n",
        "    docs = collection_visuals_segment_clusters.stream()\n",
        "    for doc in docs:\n",
        "      doc.reference.delete()\n",
        "\n",
        "    print(\"Collection visuals_segment_clusters deleted successfully!\")\n",
        "    init_visual_segment()\n",
        "\n",
        "  else:\n",
        "    print(\"Skipping firebase visuals_segment_clusters config recreation since flag_reinitialize_firebase is set to TRUE.\")\n",
        "else:\n",
        "  print(\"Collection visuals_segment_clusters does not exist.\")\n",
        "  init_visual_segment()\n",
        "\n",
        "# Get a reference to the collection\n",
        "collection_banner_template = db.collection('banner_template')\n",
        "\n",
        "# Check if the collection exists\n",
        "if collection_banner_template.get():\n",
        "  if(flag_reinitialize_firebase):\n",
        "    print(\"Collection banner_template exists. Deleting...\")\n",
        "\n",
        "    # Delete all documents in the collection\n",
        "    docs = collection_banner_template.stream()\n",
        "    for doc in docs:\n",
        "      doc.reference.delete()\n",
        "\n",
        "    print(\"Collection banner_template deleted successfully!\")\n",
        "    init_banner_template()\n",
        "  else:\n",
        "    print(\"Skipping firebase banner_template config recreation since flag_reinitialize_firebase is set to TRUE.\")\n",
        "else:\n",
        "  print(\"Collection banner_template does not exist.\")\n",
        "  init_banner_template()"
      ],
      "metadata": {
        "id": "V9ZNIo4VdbVK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730341592339,
          "user_tz": -480,
          "elapsed": 2639,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "ac643553-43b5-41a9-8c4d-333627072c6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping firebase visuals_segment_clusters config recreation since flag_reinitialize_firebase is set to TRUE.\n",
            "Skipping firebase banner_template config recreation since flag_reinitialize_firebase is set to TRUE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section - Main Business Logic"
      ],
      "metadata": {
        "id": "kHmv3dT08a31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Demo Notebook Configuration Step 2A - Firestore Functions\n",
        "\n",
        "def get_visual_segments_from_db():\n",
        "\n",
        "  try:\n",
        "    collection_ref = collection_visuals_segment_clusters\n",
        "    docs = collection_ref.stream()\n",
        "\n",
        "    visual_segments = []\n",
        "    for doc in docs:\n",
        "        visual_segments.append(doc.to_dict())\n",
        "\n",
        "    return visual_segments\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred while retrieving visual segments: {e}\")\n",
        "    return []  # Return an empty list in case of an error\n",
        "\n",
        "def get_visual_segments_list():\n",
        "    return [segment['visualsegment'] for segment in get_visual_segments_from_db()]\n",
        "\n",
        "def get_visual_segments_config(visual_segment_name):\n",
        "    for segment in get_visual_segments_from_db():\n",
        "      if segment['visualsegment'] == visual_segment_name:\n",
        "        return segment\n",
        "\n",
        "def add_or_update_visual_segment(segment_data):\n",
        "  try:\n",
        "      visual_segment_key = segment_data['visualsegment']\n",
        "      doc_ref = collection_visuals_segment_clusters.document(visual_segment_key)\n",
        "\n",
        "      if doc_ref.get().exists:\n",
        "          # Update the existing document\n",
        "          doc_ref.update(segment_data)\n",
        "          print(f\"Visual segment '{visual_segment_key}' updated successfully.\")\n",
        "          return \"updated\"\n",
        "      else:\n",
        "          # Create a new document\n",
        "          doc_ref.set(segment_data)\n",
        "          print(f\"Visual segment '{visual_segment_key}' created successfully.\")\n",
        "          return \"created\"\n",
        "\n",
        "  except Exception as e:\n",
        "      error_message = f\"An error occurred: {e}\"\n",
        "      print(error_message)\n",
        "      return error_message\n",
        "\n",
        "def add_or_update_bannertemplate(template_data):\n",
        "  try:\n",
        "      banner_template_key = template_data['bannertemplate']\n",
        "      doc_ref = collection_banner_template.document(banner_template_key)\n",
        "\n",
        "      if doc_ref.get().exists:\n",
        "          # Update the existing document\n",
        "          doc_ref.update(template_data)\n",
        "          print(f\"Banner template '{banner_template_key}' updated successfully.\")\n",
        "          return \"updated\"\n",
        "      else:\n",
        "          # Create a new document\n",
        "          doc_ref.set(template_data)\n",
        "          print(f\"Banner template '{banner_template_key}' created successfully.\")\n",
        "          return \"created\"\n",
        "\n",
        "  except Exception as e:\n",
        "      error_message = f\"An error occurred: {e}\"\n",
        "      print(error_message)\n",
        "      return error_message\n",
        "\n",
        "def get_bannertemplate_from_db():\n",
        "\n",
        "  try:\n",
        "    collection_ref = collection_banner_template\n",
        "    docs = collection_ref.stream()\n",
        "\n",
        "    banner_template = []\n",
        "    for doc in docs:\n",
        "        banner_template.append(doc.to_dict())\n",
        "\n",
        "    return banner_template\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred while retrieving visual segments: {e}\")\n",
        "    return []  # Return an empty list in case of an error\n",
        "\n",
        "def get_bannertemplate_list():\n",
        "    return [template['bannertemplate'] for template in get_bannertemplate_from_db()]\n",
        "\n",
        "def get_bannertemplate_config(bannertemplate):\n",
        "    for template in get_bannertemplate_from_db():\n",
        "      if template['bannertemplate'] == bannertemplate:\n",
        "        return template"
      ],
      "metadata": {
        "id": "zayJxGLFe-sT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Main Business Logic Option 2B [Optimal] - Background removal with rembg and alpha_matting Masking + Binary Masked White space Removal\n",
        "\n",
        "# delete_all_files(LOCAL_OUTPUT_DIR_ACTOR)\n",
        "\n",
        "flag_execute_background_removal = False #@param {type:\"boolean\"}\n",
        "\n",
        "from rembg import remove, new_session\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import io\n",
        "\n",
        "def remove_background(input_path, output_path, mask_path, margin=10, alpha_threshold=10):\n",
        "    # Open the input image\n",
        "    with open(input_path, 'rb') as input_file:\n",
        "        input_data = input_file.read()\n",
        "\n",
        "    # Create a session with the u2net model (good for detecting objects)\n",
        "    # <Shanky optimization comments> U2Net excels at accurate and detailed salient object detection, enabling high-quality background removal with preserved fine details and complex edge structures.\n",
        "    session = new_session(\"u2net\")\n",
        "\n",
        "    # Remove the background\n",
        "    # <Shanky code optimization comments> enables alpha matting for smoother edges. Alpha matting is a technique for determining partial transparency of pixels in an image, especially at object edges, to create smooth and realistic transitions between foreground and background.\n",
        "    # <Shanky code optimization comments> alpha_matting_foreground_threshold high value (close to 255, which is pure white) is chosen because: a) It ensures that only pixels that are very likely to be part of the foreground are immediately classified as such (b) ensure that the solid parts of the  dress and the actor's skin are definitely classified as foreground\n",
        "    # <Shanky code optimization comments> alpha_matting_background_threshold low value (close to 0, which is pure black) is chosen because: a) It ensures that only pixels that are very likely to be part of the background are immediately classified as such (b) we generate actor images with white background to optimize output, avoiding black or dark dress colors\n",
        "    # <Shanky code optimization comments> alpha_matting_erode_size=10 parameter in rembg controls the size of the transition area between definite foreground and background for alpha matting. Useful for preserving details around actor dress and the hair or held objects, ensuring smooth transitions and preserved details.\n",
        "    output_data = remove(input_data,\n",
        "                         session=session,\n",
        "                         alpha_matting=True,\n",
        "                         alpha_matting_foreground_threshold=230,\n",
        "                         alpha_matting_background_threshold=10,\n",
        "                         alpha_matting_erode_size=10)\n",
        "\n",
        "    # Open the output image and convert to numpy array\n",
        "    output_image = Image.open(io.BytesIO(output_data)).convert(\"RGBA\")\n",
        "    output_array = np.array(output_image)\n",
        "\n",
        "    # Extract the alpha channel\n",
        "    alpha = output_array[:, :, 3]\n",
        "\n",
        "    # Apply threshold to alpha channel for a binary mask filter\n",
        "    # <Shanky code optimization comments> Using alpha_threshold to ensure excess white space in top or sides is removed. 2C had problem of excess white space in top\n",
        "    alpha_threshold_mask = alpha > alpha_threshold\n",
        "\n",
        "    # Find the bounding box of the non-transparent area\n",
        "    rows = np.any(alpha_threshold_mask, axis=1)\n",
        "    cols = np.any(alpha_threshold_mask, axis=0)\n",
        "\n",
        "    if np.any(rows) and np.any(cols):  # Check if there's any content left after thresholding\n",
        "        ymin, ymax = np.where(rows)[0][[0, -1]]\n",
        "        xmin, xmax = np.where(cols)[0][[0, -1]]\n",
        "\n",
        "        # Add margin\n",
        "        height, width = alpha.shape\n",
        "        ymin = max(0, ymin - margin)\n",
        "        ymax = min(height, ymax + margin)\n",
        "        xmin = max(0, xmin - margin)\n",
        "        xmax = min(width, xmax + margin)\n",
        "\n",
        "        # Crop the image\n",
        "        cropped_image = output_image.crop((xmin, ymin, xmax, ymax))\n",
        "\n",
        "        # Save the cropped output image with transparent background\n",
        "        cropped_image.save(output_path)\n",
        "\n",
        "        # Crop and save the mask\n",
        "        mask_image = Image.fromarray(alpha)\n",
        "        cropped_mask = mask_image.crop((xmin, ymin, xmax, ymax))\n",
        "        cropped_mask.save(mask_path)\n",
        "\n",
        "        print(f\"Background removed image saved to {output_path}\")\n",
        "        print(f\"Mask saved to {mask_path}\")\n",
        "    else:\n",
        "        print(\"No content found after applying threshold. Saving original image.\")\n",
        "        output_image.save(output_path)\n",
        "        Image.fromarray(alpha).save(mask_path)\n",
        "\n",
        "if(flag_execute_background_removal):\n",
        "\n",
        "  list_input_files = get_filepath_in_folder_nested(os.path.join(LOCAL_INPUT_DIR_ARTEFACTS, \"Actors\"))\n",
        "\n",
        "  for input_path in list_input_files:\n",
        "    input_file = os.path.basename(input_path)\n",
        "    output_path = os.path.join(LOCAL_OUTPUT_DIR_ACTOR, f\"NoBg_{input_file}\")\n",
        "    mask_path = os.path.join(LOCAL_OUTPUT_DIR_ACTOR, f\"Mask_{input_file}\")\n",
        "    remove_background(input_path, output_path, mask_path)"
      ],
      "metadata": {
        "id": "q2eFX8JpoXRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Main Business Logic 2C - Define Gridlines For Background Templates\n",
        "\n",
        "flag_execute_bannertemplate_gridcreation = True #@param {type:\"boolean\"}\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# <Shanky Comments> Below function was originally created for supporting automated boundary identification for backgrund and section. Retaining since manual grid is still useful with template config UI\n",
        "def overlay_grid_with_coordinates(image_path, output_path, grid_size=50):\n",
        "\n",
        "  input_image = cv2.imread(image_path)\n",
        "\n",
        "  img_with_grid = input_image.copy()\n",
        "\n",
        "  height, width = img_with_grid.shape[:2]\n",
        "\n",
        "  # Primary Gridlines\n",
        "  for x in range(0, width, grid_size):\n",
        "      cv2.line(img_with_grid, (x, 0), (x, height), (0, 255, 0), 2)\n",
        "  for y in range(0, height, grid_size):\n",
        "      cv2.line(img_with_grid, (0, y), (width, y), (0, 255, 0), 2)\n",
        "\n",
        "  # Secondary Gridlines (to support better grid selection)\n",
        "  for x in range(50, width, grid_size):\n",
        "      cv2.line(img_with_grid, (x, 0), (x, height), (255, 255, 255), 1)\n",
        "  for y in range(50, height, grid_size):\n",
        "      cv2.line(img_with_grid, (0, y), (width, y), (255, 255, 255), 1)\n",
        "\n",
        "  for x in range(0, width, grid_size):\n",
        "      for y in range(0, height, grid_size):\n",
        "        # Put X and Y on separate lines with 10px spacing\n",
        "        text_x = f\"{x}\"\n",
        "        text_y = f\"{y}\"\n",
        "\n",
        "        # Calculate text height to position Y label correctly\n",
        "        (_, text_height), _ = cv2.getTextSize(text_x, cv2.FONT_HERSHEY_SIMPLEX + cv2.FONT_ITALIC, 0.8, 1)\n",
        "\n",
        "        cv2.putText(img_with_grid, text_x, (x + 5, y + 25), cv2.FONT_HERSHEY_SIMPLEX + cv2.FONT_ITALIC, 0.8, (0, 0, 0), 1)\n",
        "        cv2.putText(img_with_grid, text_y, (x + 5, y + 25 + text_height + 5), cv2.FONT_HERSHEY_SIMPLEX + cv2.FONT_ITALIC, 0.8, (0, 0, 0), 1)\n",
        "\n",
        "  success = cv2.imwrite(output_path, img_with_grid)\n",
        "  return success, height, width\n",
        "\n",
        "# <Shanky Comments> Below function deprectated, no longer necessary to do automated boundary identification for section template since we are using manual boundary with UI\n",
        "def find_section_template_in_bg(scene_path, template_path):\n",
        "    # Read the images\n",
        "    scene = cv2.imread(scene_path)\n",
        "    template = cv2.imread(template_path)\n",
        "\n",
        "    # Perform template matching to compare section to the background\n",
        "    result = cv2.matchTemplate(scene, template, cv2.TM_CCOEFF_NORMED)\n",
        "\n",
        "    # Find the best match\n",
        "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
        "\n",
        "    # Get the coordinates of the best match\n",
        "    top_left = max_loc\n",
        "    bottom_right = (top_left[0] + template.shape[1], top_left[1] + template.shape[0])\n",
        "\n",
        "    return top_left\n",
        "\n",
        "if(flag_execute_bannertemplate_gridcreation):\n",
        "\n",
        "  list_input_files = get_filenames_in_folder(LOCAL_INPUT_DIR_BG)\n",
        "\n",
        "  template_list = get_bannertemplate_list()\n",
        "\n",
        "  for input_file in list_input_files:\n",
        "\n",
        "    template = os.path.splitext(input_file)[0]\n",
        "\n",
        "    if template in template_list:\n",
        "        print(f\"Template '{template}' exists.\")\n",
        "    else:\n",
        "        print(f\"Template '{template}' is new, Initializing configuration..\")\n",
        "        background_path = f\"{LOCAL_INPUT_DIR_BG}/{input_file}\"\n",
        "        background_grid_path = f\"{LOCAL_OUTPUT_DIR_BG}/Grid_{input_file}\"\n",
        "        opstatus, height, width = overlay_grid_with_coordinates(background_path, background_grid_path, 100)\n",
        "\n",
        "        banner_config_data = {}\n",
        "        banner_config_data[\"bannertemplate\"] = f\"{os.path.splitext(input_file)[0]}\"\n",
        "        banner_config_data[\"background_size\"] = {\"height\": height, \"width\": width}\n",
        "\n",
        "        add_or_update_bannertemplate(banner_config_data)"
      ],
      "metadata": {
        "id": "fBx4dL1w1CH2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730344436584,
          "user_tz": -480,
          "elapsed": 339,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a7b91f3-3f54-4a10-d62b-a14e1c420d2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Template 'Template2' exists.\n",
            "Template 'Template1' exists.\n",
            "Template 'Template3' exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AthNHwmCfNFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Main Business Logic 2D - System Font Check\n",
        "\n",
        "# Import the IPython display module\n",
        "from IPython.display import display\n",
        "\n",
        "from pyfonts import load_font\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "# Print all available fonts and their paths after loading with PyFonts\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "fonts = fm.findSystemFonts(fontpaths=None, fontext='ttf')\n",
        "for font in fonts:\n",
        "  print(font)\n",
        "\n",
        "font = ImageFont.truetype(\"LiberationSans-Bold\", 36) # Adjust size as needed\n",
        "# Create a new image and draw the text\n",
        "image = Image.new('RGB', (400, 100), color = (255, 255, 255))\n",
        "draw = ImageDraw.Draw(image)\n",
        "draw.text((10, 10), \"Sample Text\", font=font, fill=(0, 0, 0))\n",
        "image.show()\n",
        "output_path = \"/content/demo/temp/output_font.png\"\n",
        "image.save(output_path)\n",
        "\n",
        "# Use IPython.display to display the image\n",
        "from IPython.display import Image\n",
        "# Create an Image object and pass it to display\n",
        "display(Image(filename=output_path))"
      ],
      "metadata": {
        "id": "-y4oOIwVyQKs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730348247721,
          "user_tz": -480,
          "elapsed": 106,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "abcb1e75-2945-4274-cc1b-bfa8392801f5"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/share/fonts/truetype/liberation/LiberationMono-Regular.ttf\n",
            "/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Italic.ttf\n",
            "/usr/share/fonts/truetype/liberation/LiberationSerif-BoldItalic.ttf\n",
            "/usr/share/fonts/truetype/liberation/LiberationSansNarrow-BoldItalic.ttf\n",
            "/usr/share/fonts/truetype/liberation/LiberationMono-BoldItalic.ttf\n",
            "/usr/share/fonts/truetype/liberation/LiberationSans-Italic.ttf\n",
            "/usr/share/fonts/truetype/liberation/LiberationSans-Bold.ttf\n",
            "/usr/share/fonts/truetype/humor-sans/Humor-Sans.ttf\n",
            "/usr/share/fonts/truetype/liberation/LiberationSerif-Regular.ttf\n",
            "/usr/share/fonts/truetype/liberation/LiberationSerif-Italic.ttf\n",
            "/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Bold.ttf\n",
            "/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf\n",
            "/usr/share/fonts/truetype/liberation/LiberationMono-Bold.ttf\n",
            "/usr/share/fonts/truetype/liberation/LiberationSans-BoldItalic.ttf\n",
            "/usr/share/fonts/truetype/liberation/LiberationSerif-Bold.ttf\n",
            "/usr/share/fonts/truetype/liberation/LiberationMono-Italic.ttf\n",
            "/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAABkCAIAAAAnqfEgAAAPEUlEQVR4nO3de1BUZR8H8N11BVyQWblkICGGiUhApgxylUJJI7WZRB1xKEQUrQZFHMJM4zKgoTVSzsAAM+IwkUigxNSaaYjcBJVRLlooCqgYF+POLuDu+8fOnPd5z144LGu8j30/f/E85znP/s4CX845e86Br1AoeAAANBBMdQEAAFwhsACAGggsAKAGAgsAqIHAAgBqILAAgBoILACgBgILAKiBwAIAaiCwAIAaCCwAoAYCCwCogcACAGogsACAGggsAKAGAgsAqIHA0pvExEQ+4ejRo1NdEcCLZsKB1dzcnJqaGhQU5OLiYmFhYWhoaGBgMGvWLHt7+9WrV3/++edXr159HoWCqoiICP4kbNu2baq3AGBihNyHtra2RkVFFRQUqD5Vuaenp6enp7m5WSKRJCUl+fj4pKenOzo66rVUAPi347qHVVtbu3Tp0h9//JHLM+CvXLni4eFRU1MzudrgRRYVFaXc0VuxYsVU1wLU4BRYQ0ND69ev7+zs5D5vb2/vxo0bZTKZroXBi2x0dDQnJ2eqqwD6cAqsvLy85uZmsickJOS3337r6OgYHR2VSqXNzc1ZWVn29vbkmPv37586dUqfxcL/SktLU6izY8cOctiOHTvUDsvMzJyqys+dOzehv38ASpwC6/z582Rzz5492dnZ/v7+lpaWQqHQ0NBw3rx5W7duraqqcnJyIkfm5eXps1h4UWRlZU11CUAlToH16NEjsunv7692mIWFRVJSkrm5ubu7e3Bw8KFDh8LDw9WOfPDgQVxcnL+/v7W1tUgkMjIysra2DggIOHbsWHd3t9pVWJ+I3b9/n8fjSaXSb7/91s3NTSwWi0SiN954IykpaXh4mFmrv78/Pj5+6dKl5ubmxsbGTk5OBw8eHBgYGHf+K1eu8Hi8wcHBjIyMFStWvPLKK0ZGRnPmzAkMDCwoKODypmkil8uLiopCQ0OdnJxmzZplaGhoY2Pj6+v79ddfT9VOx4RKamlpEYvFzBslEAjKy8tV5/zpp5/I99PS0rK9vX337t3KpkQiYUZevHiRGfbDDz88300F2qk9WGBZvnw5uUpycjKXtdQaGxuLiYkRCjV+OikWi/Py8lRXjI6OJoddv369s7PT2dlZdQYPD4/h4WGFQvH48WMHBwfVAfPnz29vb9c+f35+fmNj47x589QWuW7dOuVLkBISEsgxKSkpqltx9erVBQsWaNp2c3Pz06dP6/zeMjgeEupcEitWHB0dZTIZOaCvr8/GxoYcc+7cOYVCERkZqemFlHJzcye/+fAC4xRY27dvJ3+qRCJRfn6+bq+3ZcsW7T+yPB5PIBAUFxezVjxw4AA5pqSkJCAgQNMMkZGRz5498/Ly0jTgnXfeYc3/xRdfkAOOHz8+d+5cLUVu2LCBNcO4gXX+/Pnp06dr33Y+n//999/r9t4yuAeWziWFhoaSYw4dOkQu/eSTT8ilO3fuVPYjsGCSOAVWaWmp6s+Wi4tLXFxcSUnJ4OAgxxcrLCwkZ7CwsCgsLOzr62tra/vyyy/JRXZ2diMjI+S6cXFx5ICIiAgtP/disXjcM8o3btzQMr+1tTWPxwsLC7tz545UKq2rq9uwYQNrBolEQs6gPbBaW1tNTU2ZpXw+/8CBA21tbVKptKysbMmSJcwiIyOjBw8ecHxL1eIYWJMpaWBggNwvMzAwaGhoUC6qrKwUCP57qsHR0XFoaIhc9/bt22R5/v7+k9lY+FfhFFgKheL999/X9JsvFAqXLFny8ccf5+TkdHZ2apnEz8+PXPHEiRPk0rfeeotc+uuvv5JLWXEgFApnzJiRkZHR39/f2tq6efNmVlWGhoZ8Pj8+Pr67u7urq+uzzz5jDUhISNAyP4/H27p1KzlALpevXr2aHMDaTdMeWGFhYeTS2NhYcmlPT8+cOXOYpSEhIRy+JxpxDKxJlnT9+nUDAwNmgKenp1wuHxkZef3115lOAwOD2tpa1ooILNAZ18AaGBhYu3YtbzwCgcDT0zMnJ2d0dJQ1w9jYmK+vr5OT09y5c83MzAwMDJqamsgBX331FTlVfHw8uVQ1UDIyMpilo6Ojr732GmvAvn37yBlWrVpFLmUd06kG4pMnT1ibwLrraPr06b29vZpmIANraGjI0NCQ/DXu7u5mTZ6SksIMEIlE3PdbVXEJLL2UxLpf8rvvvmO9CceOHVN9aQQW6Izrle7GxsaFhYW5ubkuLi5ahsnl8oqKii1btjg4ONy6dYtcNG3atMuXL9fX1z948KC7u1smk82fP58cYGVlRTa1f2RmZWVFnkYRCoVBQUHkAKFQGBMTQ/aw9sK0z798+fLZs2ezOt3c3CwtLZnm6OjozZs3tUzCKC0tJa+hXbx4sZmZGWvMypUrma+HhoYuXrzIZWad6aWkqKgo8kxibGxsYmIiufqePXv0WTT8603g5meBQLBp06abN2/W19cnJSWtXLly5syZmgY3Nzd7enqqPfnFMjY2Njw83N/fz7osfmRkRMtavr6+06ZNI3teffVVsrlo0SJzc3MtA8irH1SRZ3AYfD5/4cKFZA9rZ0GT+vp6smlra6s6hrWHWFtby2VmnemlJD6ff+rUqZdeeknZJL+JFhYW2dnZfD5fbxUDTOjmZ4aTk5OTk1NsbKxcLm9oaKiqqqqsrLxw4cLDhw/JYYODgyEhIU1NTeTnUHK5vLi4+OzZszdu3Ghpaenr65PL5TrUoPoLRu778Hg81mX3qgMUWm+KfPnll9X2W1hYkM2///5be51KrIvLzpw5M+5vMsco1Jm+Spo9e/bJkycDAwNZ72dmZiZrlxlg8nQJLIZAIHB2dnZ2dg4PD1coFBKJJDo6urGxkRnQ0tIikUjWrFmjbDY1NQUFBXE8jNKO+avOIE8A83g81QMc1gDtRCKR2n7yvA9vvN00Rn9/P/eXVnr69OlEV5kQPZbk6upqYmJCTmhpaanp6mKAydDbA/z4fP7q1asrKytZR17Miequri4/Pz+1acXn86dPnz6hQHnepFKp2n5WQhkbG3OZTcuxsyY6BMqE6KskhULx0UcfsRZ1dnayLsUC0IvxA6u6ujozM3P37t0rVqywsrJSex8Gw9TUNDg4mOxh/iwfPXr08ePHTL9QKIyLi6urq1MeFY6MjGRnZ+u0Cc9FR0eH2v6//vqLbLJOk2nCOpAMDg4e99OQiooKnYv/J0v65ptvLly4oNqfnZ2dm5v7vKqHf6vxDwkjIyOrqqqYZlpampYryHk8HuuclFgsVn7xyy+/kP2HDx/eu3cv2dPV1TVuMf8Ytee85XL5nTt3yB7Wzd6aLF68mGyy7s2cEnop6datW/v372eaq1at6u3traysVDYjIiKWLVum6fYmAB2Mv4f1wQcfkM2cnJyTJ09qGtzZ2cl6pMyiRYuUXzx58oTsX7ZsGWtd1k3F2k+KP2+XLl1SPWVTVlbW09PDNEUikfaLPBju7u4zZsxgmjU1NeQ8SgUFBWKxeOHChX5+fps2bSorK9Otco4mX5JUKg0ODmY+Fpw5c2Z6enpmZiZzaN/X17d58+axsTHtlWg6+gZQNX5gbd++nXUCOzQ0dO3atWfPnm1ra5PJZM+ePevp6bl27drhw4ddXV3b2tqYkSKR6L333lN+bWJiQk7S0tJCNrOysn7//Xeyp6+vb6Ibo0cymYx196JcLo+Pjyd73n33XfJ3XguRSPThhx8yzcHBwdTUVNbkx48f7+3t/eOPPy5fvlxcXKzlhmS9mHxJMTEx5LURycnJtra2ixYtio2NZTqrqqpYN13xeDzW3Yv37t179uzZpDcI/h24XF2an5+v2+RHjhxhJtm4cSO5yN7evrKyUiqVNjU1KU/QWllZ+fr6MgNsbW3Je9DGvbWYdcgZFhbGGqB8Ig3D3d2dXMqaX3mKZ+fOnXfv3pXJZHV1devXrycH8Pn8mpoaLTOwKlQ+lYVZKhAIYmJi7t27J5VKGxsbWTcqJiUlcfm+aMLx1pzJlCSRSMjLILy9veVyuXKRTCZjdquV05aUlJDr9vf3kzcb8ni8/fv3P336tK+v79GjR5PZcHjhcb01Jy0tTcszYdTatWsX80OsUCi0H+MIBILz588fO3aM7LS1tfX19VXmwj8cWHFxcazrtliioqJY849bYVFR0biPRuDxeOvWrRsbG+P4fVGL+9MadCups7OTvMbKyMjozp075LQVFRVkJNnY2LDu+/Hw8FD7Qnv37p3MhsMLj+tlDTt27KioqGA9GEsTe3v7/Pz8EydOkH+Evby8UlJSWH9alUxMTM6dOxcQELBt2zblYxKUWltbS0tL1T5v73kTi8USiUTtCWM+n//pp5/q8G8H16xZc+nSJS0noZW3E505c4Z1Ef/zo1tJ4eHh7e3tTPPgwYOs5455eHjs2rWLaT58+JD1L8WOHDnyf3UVC9BiAjtNbm5uJSUlDQ0NBQUF165du337dldXlzJNZs6cKRaLHRwcXF1dAwMDvby81F42HR0d7ePjk5qaWl5e3t7ebmxsbGdnFxgYuGvXLuVfbFNT0+rq6sTExNra2p6eHjMzswULFkzJx0xjY2NvvvlmbW1tRkZGXl7e3bt3h4eHraysvL29IyIiPD09dZvW29v7zz//PH369M8//1xdXd3R0TE0NCQWi+fPn//222+Hh4fb2dnpdTv0X1JGRsbZs2eZ5uLFi/ft26c6bXJyclFRUWtrq7JZWFiYnp7O7Pr5+PiUl5cnJCSUlZX19vaamJiYmZk5OzvjclPQjq+Y0g/j/n8kJiaSz/BLSUlhPYMUAKYc/lU9AFADgQUA1EBgAQA1EFgAQA0EFgBQA4EFANTAZQ0AQA3sYQEANRBYAEANBBYAUAOBBQDUQGABADUQWABADQQWAFADgQUA1EBgAQA1EFgAQA0EFgBQA4EFANRAYAEANRBYAEANBBYAUAOBBQDUQGABADUQWABADQQWAFADgQUA1EBgAQA1EFgAQA0EFgBQA4EFANRAYAEANRBYAEANBBYAUAOBBQDUQGABADUQWABADQQWAFADgQUA1EBgAQA1EFgAQA0EFgBQA4EFANRAYAEANRBYAEANBBYAUAOBBQDUQGABADUQWABADQQWAFADgQUA1EBgAQA1EFgAQA0EFgBQA4EFANRAYAEANf4DkuBL8TxfgWsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Main Business Logic 2E - Banner Generation Core Functions\n",
        "\n",
        "import IPython.display as open_image\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from string import ascii_letters\n",
        "import textwrap\n",
        "\n",
        "def get_font_metrics(font):\n",
        "    ascent, descent = font.getmetrics()\n",
        "    avg_char_width = sum(font.getbbox(char)[2] for char in ascii_letters) / len(ascii_letters)\n",
        "    return ascent, descent, avg_char_width\n",
        "\n",
        "def wrap_text_custom(text, font, max_width):\n",
        "    words = text.split()\n",
        "    lines = []\n",
        "    current_line = []\n",
        "    current_width = 0\n",
        "\n",
        "    for word in words:\n",
        "        word_width = font.getbbox(word)[2]\n",
        "        space_width = font.getbbox(' ')[2]\n",
        "\n",
        "        if current_width + word_width <= max_width:\n",
        "            current_line.append(word)\n",
        "            current_width += word_width + space_width\n",
        "        else:\n",
        "            if current_line:\n",
        "                lines.append(' '.join(current_line))\n",
        "            current_line = [word]\n",
        "            current_width = word_width + space_width\n",
        "\n",
        "    if current_line:\n",
        "        lines.append(' '.join(current_line))\n",
        "\n",
        "    return lines\n",
        "\n",
        "def get_font_size(textarea, text, font_name, pixel_gap=2):\n",
        "    text_width, text_height = int(textarea[0]), int(textarea[1])\n",
        "\n",
        "    for point_size in range(5, 300):\n",
        "        font = ImageFont.truetype(font_name, point_size)\n",
        "        ascent, descent, avg_char_width = get_font_metrics(font)\n",
        "\n",
        "        wrapped_lines = wrap_text_custom(text, font, text_width)\n",
        "\n",
        "        total_height = (ascent + descent + pixel_gap) * len(wrapped_lines) - pixel_gap\n",
        "\n",
        "        if total_height >= text_height:\n",
        "            point_size -= 1\n",
        "            font = ImageFont.truetype(font_name, point_size)\n",
        "            wrapped_lines = wrap_text_custom(text, font, text_width)\n",
        "            break\n",
        "\n",
        "    return wrapped_lines, point_size\n",
        "\n",
        "def place_singleline_text_overlay_on_background(overlay_image_path, text, initial_font_size, overlay_config, font_name, text_color, alignment, margin=10):\n",
        "    x, y = overlay_config['x'], overlay_config['y']\n",
        "    width, height = overlay_config['width'], overlay_config['height']\n",
        "\n",
        "    with Image.open(overlay_image_path) as img:\n",
        "        draw = ImageDraw.Draw(img)\n",
        "\n",
        "        # Function to get text width\n",
        "        def get_text_width(font):\n",
        "            return draw.textbbox((0, 0), text, font=font)[2]\n",
        "\n",
        "        # Start with the initial font size and decrease if necessary\n",
        "        font_size = initial_font_size\n",
        "        font = ImageFont.truetype(font_name, font_size)\n",
        "        text_width = get_text_width(font)\n",
        "        print(f\"Processing text {text} with initial font size {initial_font_size}\")\n",
        "\n",
        "        # Decrease font size until text fits within max_width (including margin)\n",
        "        while text_width > (width - 2 * margin) and font_size > 1:\n",
        "            print(f\"Optimizing fontsize to fit, reducing.. \")\n",
        "            font_size -= 1\n",
        "            font = ImageFont.truetype(font_name, font_size)\n",
        "            text_width = get_text_width(font)\n",
        "        print(f\"Final text {text} with font size {font_size}\")\n",
        "\n",
        "        # Calculate text position and use Pillow's built-in alignment\n",
        "        if alignment == 'center':\n",
        "            anchor = 'mm'  # middle-middle\n",
        "            text_x = x + width // 2\n",
        "        elif alignment == 'right':\n",
        "            anchor = 'rm'  # right-middle\n",
        "            text_x = x + width - margin\n",
        "        else:  # left alignment\n",
        "            anchor = 'lm'  # left-middle\n",
        "            text_x = x + margin\n",
        "\n",
        "        # Calculate vertical position (center of the height)\n",
        "        text_y = y + height // 2\n",
        "\n",
        "        # Draw the text using Pillow's alignment feature\n",
        "        draw.text((text_x, text_y), text, font=font, fill=text_color, anchor=anchor)\n",
        "\n",
        "        # Save the result\n",
        "        img.save(overlay_image_path)\n",
        "        return img\n",
        "\n",
        "\n",
        "def place_multiline_text_overlay_on_background(overlay_image_path, text, overlay_config, font_name, text_color, alignment, margin=10):\n",
        "\n",
        "    # text_color = (0, 0, 0)  # Black color in RGB\n",
        "\n",
        "    # font_name for Colab\n",
        "    # Humor-Sans.ttf\n",
        "    # LiberationSans-Regular.ttf\n",
        "    # LiberationMono-Regular.ttf\n",
        "    # LiberationSerif-Regular.ttf\n",
        "    # LiberationSansNarrow-Regular.ttf\n",
        "\n",
        "    # LiberationSans-Italic.ttf\n",
        "    # LiberationMono-Italic.ttf\n",
        "    # LiberationSerif-Italic.ttf\n",
        "\n",
        "    # LiberationMono-BoldItalic.ttf\n",
        "    # LiberationSerif-BoldItalic.ttf\n",
        "    # LiberationSansNarrow-Italic.ttf\n",
        "\n",
        "    # LiberationSansNarrow-BoldItalic.ttf\n",
        "    # LiberationSans-BoldItalic.ttf\n",
        "\n",
        "    # LiberationSans-Bold.ttf\n",
        "    # LiberationMono-Bold.ttf\n",
        "    # LiberationSerif-Bold.ttf\n",
        "    # LiberationSansNarrow-Bold.ttf\n",
        "\n",
        "    x, y = overlay_config['x'], overlay_config['y']\n",
        "    width, height = overlay_config['width'], overlay_config['height']\n",
        "\n",
        "    with Image.open(overlay_image_path) as img:\n",
        "        draw = ImageDraw.Draw(img)\n",
        "\n",
        "        wrapped_lines, font_size = get_font_size((width, height), text, font_name, margin)\n",
        "        font = ImageFont.truetype(font_name, font_size)\n",
        "\n",
        "        ascent, descent, _ = get_font_metrics(font)\n",
        "        line_height = ascent + descent + margin\n",
        "\n",
        "        current_y = y\n",
        "        for line in wrapped_lines:\n",
        "            if alignment == 'center':\n",
        "                line_bbox = draw.textbbox((0, 0), line, font=font)\n",
        "                line_width = line_bbox[2] - line_bbox[0]\n",
        "                line_x = x + (width - line_width) // 2\n",
        "            elif alignment == 'right':\n",
        "                line_bbox = draw.textbbox((0, 0), line, font=font)\n",
        "                line_width = line_bbox[2] - line_bbox[0]\n",
        "                line_x = x + width - line_width\n",
        "            else:  # left alignment\n",
        "                line_x = x\n",
        "\n",
        "            draw.text((line_x, current_y), line, font=font, fill=text_color)\n",
        "            current_y += line_height\n",
        "\n",
        "        # Save the result\n",
        "        img.save(overlay_image_path)\n",
        "        return img\n",
        "\n",
        "def place_image_overlay_on_background(overlay_image_path, background_image_path, overlay_config, output_path):\n",
        "\n",
        "  # Placement config\n",
        "  target_x = overlay_config['x']\n",
        "  target_y = overlay_config['y']\n",
        "  target_width = overlay_config['width']\n",
        "  target_height = overlay_config['height']\n",
        "\n",
        "  # Open images\n",
        "  background_image = Image.open(background_image_path).convert('RGBA')  # Convert to RGBA\n",
        "\n",
        "  overlay_image = Image.open(overlay_image_path).convert('RGBA')  # Convert to RGBA\n",
        "\n",
        "  # Calculate aspect ratio\n",
        "  overlay_image_aspect_ratio = overlay_image.width / overlay_image.height\n",
        "\n",
        "  print(f\"Original size of overlay image {overlay_image_path}, Aspect Ratio - {overlay_image_aspect_ratio}, Size - {background_image.size}\")\n",
        "\n",
        "  # Resize to meet target height, maintaining aspect ratio, using LANCZOS\n",
        "  new_width = int(target_height * overlay_image_aspect_ratio)\n",
        "  resized_overlay_image = overlay_image.resize((new_width, target_height), Image.LANCZOS)\n",
        "  print(f\"Resized overlay image to Size - {resized_overlay_image.size}\")\n",
        "\n",
        "  # Check if resized width exceeds target width, and resize again if needed\n",
        "  if new_width > target_width:\n",
        "      new_height = int(target_width / overlay_image_aspect_ratio)\n",
        "      resized_overlay_image = overlay_image.resize((target_width, new_height), Image.LANCZOS)\n",
        "      print(f\"Width exceeds boundary, adjusting overlay image with width / height - {target_width} / {new_height} to Size - {resized_overlay_image.size}\")\n",
        "\n",
        "  # Calculate centered coordinates\n",
        "  final_x = target_x + (target_width - resized_overlay_image.width) // 2\n",
        "  final_y = target_y + (target_height - resized_overlay_image.height) // 2\n",
        "\n",
        "  # Paste actor image onto background\n",
        "  background_image.paste(resized_overlay_image, (final_x, final_y), resized_overlay_image)  # Use mask for transparency\n",
        "\n",
        "  # Save the result (optional)\n",
        "  background_image.save(output_path)  # Save as PNG to preserve transparency\n",
        "\n",
        "  return background_image\n",
        "\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import textwrap\n",
        "\n",
        "def create_marketing_banner_baseline(background_path, background_config, image_inputs: dict, text_inputs: dict, output_path):\n",
        "\n",
        "  config = background_config\n",
        "\n",
        "  # Open background image\n",
        "  background = Image.open(background_path)\n",
        "  width, height = background.size\n",
        "\n",
        "  if 'actor_position' in background_config and 'actor_path' in image_inputs:\n",
        "    # Process Actor overlay\n",
        "    place_image_overlay_on_background (image_inputs['actor_path'], background_path, background_config['actor_position'], output_path)\n",
        "\n",
        "  if 'logo_position' in background_config and 'logo_path' in image_inputs:\n",
        "    # Process Logo overlay\n",
        "    place_image_overlay_on_background (image_inputs['logo_path'], output_path, background_config['logo_position'], output_path)\n",
        "\n",
        "  if 'graphic1_position' in background_config and 'graphic1_path' in image_inputs:\n",
        "    # Process Logo overlay\n",
        "    place_image_overlay_on_background (image_inputs['graphic1_path'], output_path, background_config['graphic1_position'], output_path)\n",
        "\n",
        "  if 'graphic2_position' in background_config and 'graphic2_path' in image_inputs:\n",
        "    # Process Logo overlay\n",
        "    place_image_overlay_on_background (image_inputs['graphic2_path'], output_path, background_config['graphic2_position'], output_path)\n",
        "\n",
        "  if 'graphic_highlight2_position' in background_config and 'graphic_highlight2_path' in image_inputs:\n",
        "    # Process Logo overlay\n",
        "    place_image_overlay_on_background (image_inputs['graphic_highlight2_path'], output_path, background_config['graphic_highlight2_position'], output_path)\n",
        "\n",
        "  if 'text_header1_position' in background_config and 'text_header1' in text_inputs:\n",
        "    # Process Text Header overlay\n",
        "    text_header = text_inputs['text_header1']\n",
        "    text_color = (0, 0, 0)\n",
        "    text_alignment=\"left\"\n",
        "    text_margin=25\n",
        "    font_name=\"LiberationSans-Bold.ttf\"\n",
        "    place_multiline_text_overlay_on_background (output_path, text_header, background_config['text_header1_position'], font_name=font_name, text_color=text_color, alignment=text_alignment, margin=text_margin)\n",
        "\n",
        "  if 'text_header2_position' in background_config and 'text_header2' in text_inputs:\n",
        "    # Process Text Header overlay\n",
        "    text_header = text_inputs['text_header2']\n",
        "    text_color = (0, 0, 0)\n",
        "    text_alignment=\"left\"\n",
        "    text_margin=25\n",
        "    font_name=\"LiberationSans-Regular.ttf\"\n",
        "    place_multiline_text_overlay_on_background (output_path, text_header, background_config['text_header2_position'], font_name=font_name, text_color=text_color, alignment=text_alignment, margin=text_margin)\n",
        "\n",
        "  if 'text_details_position' in background_config and 'text_details' in text_inputs:\n",
        "    # Process Text Detail overlay\n",
        "    text_header = text_inputs['text_details']\n",
        "    text_color = (0, 0, 0)\n",
        "    text_alignment=\"left\"\n",
        "    text_margin=25\n",
        "    font_name=\"LiberationSans-Regular.ttf\"\n",
        "    place_multiline_text_overlay_on_background (output_path, text_header, background_config['text_details_position'], font_name=font_name, text_color=text_color, alignment=text_alignment, margin=text_margin)\n",
        "\n",
        "  if 'text_highlight1_position' in background_config and 'text_highlight1' in text_inputs:\n",
        "    # Process Text Highlight overlay\n",
        "    text_header = text_inputs['text_highlight1']\n",
        "    text_color = (0, 0, 0)\n",
        "    text_alignment=\"center\"\n",
        "    text_margin=5\n",
        "    font_name=\"LiberationSansNarrow-Bold.ttf\"\n",
        "    place_singleline_text_overlay_on_background (output_path, text_header, 100, background_config['text_highlight1_position'], font_name=font_name, text_color=text_color, alignment=text_alignment, margin=text_margin)\n",
        "\n",
        "  if 'text_highlight3_position' in background_config and 'text_highlight3' in text_inputs:\n",
        "    # Process Text Highlight overlay\n",
        "    text_header = text_inputs['text_highlight3']\n",
        "    text_color = (0, 0, 0)\n",
        "    text_alignment=\"center\"\n",
        "    text_margin=20\n",
        "    font_name=\"LiberationSansNarrow-Bold.ttf\"\n",
        "    place_singleline_text_overlay_on_background (output_path, text_header, 120, background_config['text_highlight3_position'], font_name=font_name, text_color=text_color, alignment=text_alignment, margin=text_margin)\n",
        "\n",
        "  if 'text_tagline_position' in background_config and 'text_tagline' in text_inputs:\n",
        "    # Process Text Tagline overlay\n",
        "    text_header = text_inputs['text_tagline']\n",
        "    text_color = (255, 0, 0)\n",
        "    text_alignment=\"center\"\n",
        "    text_margin=25\n",
        "    font_name=\"LiberationMono-Italic\"\n",
        "    place_singleline_text_overlay_on_background (output_path, text_header, 25, background_config['text_tagline_position'], font_name=font_name, text_color=text_color, alignment=text_alignment, margin=text_margin)\n",
        "\n",
        "  if 'text_action_position' in background_config and 'text_action' in text_inputs:\n",
        "    # Process Text Tagline overlay\n",
        "    text_header = text_inputs['text_action']\n",
        "    text_color = (255, 255, 255)\n",
        "    text_alignment=\"center\"\n",
        "    text_margin=25\n",
        "    font_name=\"LiberationMono-Bold.ttf\"\n",
        "    place_singleline_text_overlay_on_background (output_path, text_header, 35, background_config['text_action_position'], font_name=font_name, text_color=text_color, alignment=text_alignment, margin=text_margin)\n",
        "\n",
        "  return output_path\n",
        "\n",
        "# # Usage example\n",
        "# banner_background = \"Template1\"\n",
        "# background_path = f\"{LOCAL_INPUT_DIR_BG}/{banner_background}.png\"\n",
        "# background_config = get_bannertemplate_config(banner_background)\n",
        "# image_inputs = {}\n",
        "# image_inputs['logo_path'] = f\"{LOCAL_INPUT_DIR_LOGO}/im3logo.png\"\n",
        "# image_inputs['actor_path'] = f\"{LOCAL_OUTPUT_DIR_ACTOR}/NoBg_Old_Woman_Individual_1.png\"\n",
        "# image_inputs['graphic1_path'] = f\"{LOCAL_INPUT_DIR_GRAPHICS}/Graphics1.png\"\n",
        "# image_inputs['graphic2_path'] = f\"{LOCAL_INPUT_DIR_GRAPHICS}/Graphics4.png\"\n",
        "# image_inputs['graphic_highlight2_path'] = f\"{LOCAL_INPUT_DIR_GRAPHICS}/50GraphicH2.png\"\n",
        "\n",
        "# output_path = \"/content/demo/temp/output_banner.png\"\n",
        "\n",
        "# text_inputs = {}\n",
        "# text_inputs['text_header1'] = \"Freedom Unlimited Apps Bundle Special Offer\"\n",
        "# text_inputs['text_header2'] = \"Enjoy the festivities with new exciting games and movies.\"\n",
        "# text_inputs['text_details'] = \"FREEDOM U ! Now Able to Access More Apps, Limitless Call to IM3 Ooredoo and Tri! Plus, 24 hours to access even more of your favorite apps, like YouTube, Instagram, TikTok, Facebook, Spotify, Joox, WhatsApp, and Line. This will be unlimited\"\n",
        "# text_inputs['text_highlight1'] = \"100 GB\"\n",
        "# text_inputs['text_highlight3'] = \"250 Ribu Only\"\n",
        "# text_inputs['text_tagline'] = \"Offer Valid for prepaid and postpaid IM3 customers.\"\n",
        "# text_inputs['text_action'] = \"BUY NOW\"\n",
        "\n",
        "# # Create the banner with Actor & Logo overlaid\n",
        "# banner = create_marketing_banner_baseline(background_path, background_config, image_inputs, text_inputs, output_path)\n",
        "\n",
        "# open_image.display(open_image.Image(filename=output_path))"
      ],
      "metadata": {
        "id": "X-48ovJR2bmZ",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730348247819,
          "user_tz": -480,
          "elapsed": 101,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section - Gradio Front End"
      ],
      "metadata": {
        "id": "jyXIaxZljR6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Gradio Front End - About Demo Tab\n",
        "\n",
        "with gr.Blocks() as ui_about_tab:\n",
        "\n",
        "  print(\"In ui_about_tab\")\n",
        "\n",
        "  gr.Markdown(\"### About this Demo\")\n",
        "  output_author = gr.Text(label=\"Author\", value = \"Shanky Ram\")\n",
        "  output_desc = gr.Text(label=\"Demo Description\", value = \"This demo demonstrates an end to end pipeline for dynamic banner generation for CVM targeting using Imagen3, Gemini and opensource python libraries like rembg\")\n",
        "\n",
        "  gr.Markdown(\"### Execute this part of the demo following below instructions -\")\n",
        "  gr.Markdown(\"\"\"\n",
        "    In Demo,\n",
        "    Step 1 - Use the \"Demo Asset Library\" to walk the customer through the building blocks for a dynamic banner generation - a library of elements for Actors / Background / Logos / Graphics / Text\n",
        "    \\n\n",
        "    Step 2 - Use the \"Demo Asset Creation\" section to demonstrate the creation of a new visual segments (tied to customer targeting needs), generation of Actors using Imagen3\n",
        "    \\n\n",
        "    Step 3 - Use the \"Demo Asset Preprocessing\" section to demonstrate the concept of removal of background from elements like Actors assets to enable overlay on top of background template\n",
        "    \\n\n",
        "    Step 4 - Use the \"Demo Banner Template\" section to illustrate the concept of banner templates and how this can be defined via a UX or even via tools like Figma\n",
        "    \\n\n",
        "    Step 5 - Use the \"Demo Banner Generation\" section to illustrate the concept of dynamic banner generation for one or more templates for one or more visual segments\n",
        "    \"\"\")\n",
        "\n",
        "visual_segment_options = get_visual_segments_list()"
      ],
      "metadata": {
        "id": "GMIvwwNNmDHX",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730348248884,
          "user_tz": -480,
          "elapsed": 1065,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6094131-25cd-494f-d56e-2c8879bc2a50"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In ui_about_tab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Gradio Front End - Demo Marketing Asset Library Tab\n",
        "\n",
        "gallery_dirname_list = [] #global variable to track selected thumbnail directory to show full image\n",
        "\n",
        "# Function to get all image files in a directory\n",
        "def get_image_files(directory):\n",
        "    image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp']\n",
        "    return [f for f in os.listdir(directory) if os.path.splitext(f)[1].lower() in image_extensions]\n",
        "\n",
        "# Function to create thumbnails\n",
        "def create_thumbnail(image_path, size=(200, 200)):\n",
        "    with Image.open(image_path) as img:\n",
        "        img.thumbnail(size, Image.Resampling.LANCZOS)  # Use a high-quality resampling filter\n",
        "        return np.array(img)\n",
        "\n",
        "# Function to update thumbnails\n",
        "def update_thumbnails(selected_folder):\n",
        "    image_files = get_image_files(selected_folder)\n",
        "    thumbnails = [create_thumbnail(os.path.join(selected_folder, img)) for img in image_files]\n",
        "    imagepath = [(os.path.join(selected_folder, img)) for img in image_files]\n",
        "    return thumbnails, imagepath\n",
        "\n",
        "# Function to display selected image\n",
        "def display_image(evt: gr.SelectData): #, selected_folder):\n",
        "    print(f\"all_thumbnails positional data {gallery_dirname_list[evt.index]}\")\n",
        "    return Image.open(gallery_dirname_list[evt.index])\n",
        "\n",
        "def select_folder(selected_files):\n",
        "    global gallery_dirname_list  # Declare gallery_dirname_list as global\n",
        "    print(f\"Selection - {selected_files}\")\n",
        "\n",
        "    if selected_files:\n",
        "        dirnames = []\n",
        "        for file_path in selected_files:\n",
        "            if os.path.isfile(file_path):\n",
        "                dirname = os.path.dirname(file_path)\n",
        "            else:\n",
        "                dirname = file_path\n",
        "            dirnames.append(dirname)\n",
        "\n",
        "        # Get unique dirnames\n",
        "        unique_dirnames = list(set(dirnames))\n",
        "\n",
        "        all_thumbnails = []\n",
        "        gallery_dirname_list = []  # Reset gallery_dirname_list\n",
        "        for dirname in unique_dirnames:\n",
        "            thumbnails, imagepath = update_thumbnails(dirname)  # Get thumbnails for the current dirname\n",
        "            all_thumbnails.extend(thumbnails)\n",
        "            gallery_dirname_list.extend(imagepath)  # Add imagepath for each thumbnail\n",
        "\n",
        "        return all_thumbnails, None  # Return only the list of thumbnails\n",
        "    return None, None  # Return None if no files are selected\n",
        "\n",
        "# Main Gradio interface\n",
        "with gr.Blocks() as ui_demo_tab_assetlibrary:\n",
        "\n",
        "    print(\"ui_demo_tab_assetlibrary\")\n",
        "\n",
        "    ROOT_FOLDER = LOCAL_INPUT_DIR_ARTEFACTS\n",
        "\n",
        "    with gr.Column(variant='panel'):\n",
        "      gr.Markdown(\"# Marketing Assets Library\")\n",
        "\n",
        "    with gr.Column(variant='panel'):\n",
        "      with gr.Row():\n",
        "          gr.Markdown(f\"**Image Library:** loaded from {ROOT_FOLDER}\")\n",
        "\n",
        "    with gr.Column(variant='panel'):\n",
        "      with gr.Row():\n",
        "          with gr.Column(scale=1):\n",
        "              file_explorer = gr.FileExplorer(root_dir=ROOT_FOLDER, ignore_glob=\"*.json\", label=\"Library Explorer\")\n",
        "\n",
        "          with gr.Column(scale=3):\n",
        "              thumbnail_gallery = gr.Gallery(label=\"Selected Image Gallery\", columns=3, rows=None, height=\"auto\")\n",
        "\n",
        "    with gr.Column(variant='panel'):\n",
        "      with gr.Row():\n",
        "          displayed_image = gr.Image(label=\"Selected Image\")\n",
        "\n",
        "    # Event handler for folder selection\n",
        "    file_explorer.change(\n",
        "        select_folder,\n",
        "        inputs=[file_explorer],\n",
        "        outputs=[thumbnail_gallery, displayed_image]\n",
        "    )\n",
        "\n",
        "    # Event handler for thumbnail selection\n",
        "    thumbnail_gallery.select(\n",
        "        display_image,\n",
        "        inputs=[],\n",
        "        outputs=[displayed_image]\n",
        "    )"
      ],
      "metadata": {
        "id": "--YE2d3DmeL3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730348249143,
          "user_tz": -480,
          "elapsed": 261,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97a1eab5-9a1e-478a-9069-3251ac62e8c8"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ui_demo_tab_assetlibrary\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Gradio Front End - Create New Marketing Asset with Imagen3\n",
        "\n",
        "selected_visual_segment = None\n",
        "\n",
        "default_model = \"imagen-3.0-generate-001\"\n",
        "default_background = \"White background\"\n",
        "default_photography = \"Studio portrait, professional lighting, DSLR camera shot, 4K\"\n",
        "default_count = 3\n",
        "default_aspectratio = \"4:3\"\n",
        "\n",
        "imagen_prompt = \"\"\n",
        "\n",
        "def generate_image_filename(directory, image_count):\n",
        "  now = datetime.datetime.now()\n",
        "  datetime_str = now.strftime(\"%d%m%H%M%S\")  # Format as ddmmHHMMSS\n",
        "  filename = f\"{directory}_{image_count}_{datetime_str}.png\"  # Create filename with .png extension\n",
        "  return filename\n",
        "\n",
        "def display_message(type, msg, duration):\n",
        "    duration = None if duration < 0 else duration\n",
        "    if type == \"error\":\n",
        "        raise gr.Error(msg, duration=duration)\n",
        "    elif type == \"info\":\n",
        "        gr.Info(msg, duration=duration)\n",
        "    elif type == \"warning\":\n",
        "        gr.Warning(msg,  duration=duration)\n",
        "\n",
        "with gr.Blocks() as ui_demo_tab_assetcreation:\n",
        "\n",
        "    print(\"ui_demo_tab_assetcreation\")\n",
        "\n",
        "    with gr.Row(variant='panel'):\n",
        "      gr.Markdown(\"# Create New Marketing Assets With Imagen3\")\n",
        "\n",
        "    with gr.Row():\n",
        "      with gr.Column(scale=1, variant='panel'):\n",
        "        # Dropdown with existing visual segments\n",
        "        visual_segment_dropdown = gr.Dropdown(choices=get_visual_segments_list(), label=\"Select Visual Segment\")\n",
        "        load_button = gr.Button(\"Load Visual Config\")\n",
        "\n",
        "      with gr.Column(scale=3, variant='panel'):\n",
        "          new_segment_input = gr.Textbox(label=\"New Visual Segment Name\")\n",
        "          create_button = gr.Button(\"Define Visual Config\")\n",
        "\n",
        "    with gr.Column(variant='panel'):\n",
        "      # Input boxes for visual segment configuration\n",
        "      with gr.Row():\n",
        "          subject_input = gr.Textbox(label=\"Subject\", placeholder = \"Describe the subject. E.g. a vibrant Indonesian woman\", lines = 2, interactive=True)\n",
        "          age_input = gr.Textbox(label=\"Age\", placeholder = \"Age of the subject. E.g. age 40-50 years old\", lines = 2, interactive=True)\n",
        "      with gr.Row():\n",
        "          clothing_input = gr.Textbox(label=\"Clothing\", placeholder = \"Clothing of the subject. E.g. wearing a traditional Balinese dress\", lines = 4, interactive=True)\n",
        "          theme_input = gr.Textbox(label=\"Theme\", placeholder = \"Theme of the visual. E.g. enjoying movie on her phone screen wearing red headphones\", lines = 4, interactive=True)\n",
        "      with gr.Row():\n",
        "          background_input = gr.Textbox(label=\"Environment Settings\", placeholder = \"White background\", interactive=True)\n",
        "          photography_input = gr.Textbox(label=\"Photography Setting\", placeholder = \"Studio portrait, professional lighting, DSLR camera shot, 4K\", interactive=True)\n",
        "      with gr.Row():\n",
        "          count_input =gr.Dropdown(choices=[1, 2, 3], label=\"# Images\", interactive=True)\n",
        "          aspectratio_input =gr.Dropdown(choices=[\"1:1\", \"3:4\", \"4:3\", \"16:9\", \"9:16\"], label=\"Aspect Ratio\", interactive=True)\n",
        "          model_input =gr.Dropdown(choices=[\"imagen-3.0-generate-001\", \"imagen-3.0-fast-generate-001\"], label=\"Imagen Models\", interactive=True)\n",
        "\n",
        "    with gr.Row(visible=False) as generate_visual_assets:\n",
        "      generate_assets_button = gr.Button(\"Click to use Imagen3 to Generate Visual Assets\")\n",
        "\n",
        "    with gr.Row(visible=False) as review_visual_assets:\n",
        "      with gr.Row(variant='panel'):\n",
        "        prompt_text = gr.Markdown()\n",
        "      with gr.Row(variant='panel'):\n",
        "        gallery = gr.Gallery(\n",
        "          label=\"Generated Images\",\n",
        "          columns=[3],\n",
        "          height=\"auto\"\n",
        "        )\n",
        "\n",
        "    with gr.Row(visible=False) as approve_visual_assets:\n",
        "      with gr.Column(variant='panel'):\n",
        "        approve_button = gr.Button(\"Save Images to Marketing Library\")\n",
        "\n",
        "    def load_config(selected_value):\n",
        "\n",
        "      if not selected_value:\n",
        "          gr.Warning(\"Please select a visual segment from the dropdown.\", duration=5)  # Trigger warning\n",
        "          return None, None, None, None, default_background, default_photography, default_count, default_aspectratio, default_model\n",
        "      # Populate input boxes and print the selected segment's configuration\n",
        "      config = get_visual_segments_config(selected_value)\n",
        "\n",
        "      global selected_visual_segment  # Declare selected_visual_segment as global\n",
        "      selected_visual_segment = selected_value\n",
        "\n",
        "      return config.get(\"subject\", \"\"), config.get(\"age\", \"\"), config.get(\"clothing\", \"\"), config.get(\"theme\", \"\"), config.get(\"background\", \"\"), config.get(\"photography\", \"\"), default_count, default_aspectratio, default_model\n",
        "\n",
        "    def create_new_segment(new_segment_name):\n",
        "        # Validation: Check if the segment name already exists\n",
        "        if not new_segment_name:\n",
        "            gr.Warning(f\"Visual segment is empty!\", duration=5)  # Throw warning\n",
        "            return None, None, None, None, default_background, default_photography, default_count, default_aspectratio, default_model\n",
        "\n",
        "        if new_segment_name in get_visual_segments_list():\n",
        "            gr.Warning(f\"Visual segment '{new_segment_name}' already exists!\", duration=5)  # Throw warning\n",
        "            return None, None, None, None, default_background, default_photography, default_count, default_aspectratio, default_model\n",
        "\n",
        "        global selected_visual_segment  # Declare selected_visual_segment as global\n",
        "        selected_visual_segment = new_segment_name\n",
        "\n",
        "        return None, None, None, None, default_background, default_photography, default_count, default_aspectratio, default_model\n",
        "\n",
        "    # Function to handle \"Generate Visual Assets\" button click\n",
        "    def generate_assets(subject, age, clothing, theme, background, photography, imagecount, aspectratio, model):\n",
        "\n",
        "        # Show a \"processing\" state while generating images\n",
        "        yield [], gr.update(value=\"Processing...\", interactive=False)  # Update the button\n",
        "\n",
        "        prompt_user_input = f\"\"\"\n",
        "          \"Subject: {subject}\"\n",
        "          \"Age: {age}\"\n",
        "          \"Clothing: {clothing}\"\n",
        "          \"Theme: {theme}\"\n",
        "          \"Environment Settings: {background}\"\n",
        "          \"Photography Setting: {photography}\"\n",
        "\n",
        "          If the subject involves multiple people, ensure that they DO NOT LOOK alike.\n",
        "        \"\"\"\n",
        "\n",
        "        print(f\"User Input : {prompt_user_input}\")\n",
        "\n",
        "        # Prompt Attribution: kkrish\n",
        "        prompt_rewrite = f\"\"\"\n",
        "          Act as a prompt engineering expert to generate a high quality prompt for Imagen3 image generation strictly following the user input below.\n",
        "\n",
        "          Extract all key information and entities required for you to rewrite the prompt retaining exact original intent without hyperbole to feed it to an image generation model.\n",
        "          Retain all inputs related to subject including age, ethinicity, gender, clothing, theme, background, photography in your output prompt\n",
        "          The input will be based for a marketing campaign description for creating posters, banners, etc.\n",
        "          Strictly do not provide any input text in the output top prompts or high confidence prompt.\n",
        "          You are only to generate image and not text on image.\n",
        "          The output should be concise, explaining all entities of what is required in the image and how it has to be generated.\n",
        "\n",
        "          Check if your response is a SINGLE high quality prompt meeting the guidelines above, before responding.\n",
        "\n",
        "          USER INPUT -\n",
        "          {prompt_user_input}\n",
        "\n",
        "          OUTPUT -\n",
        "        \"\"\"\n",
        "\n",
        "        global imagen_prompt\n",
        "        imagen_prompt = invoke_gemini_for_text(prompt_rewrite)\n",
        "\n",
        "        print(f\"Generated Imagen3 prompt with Gemimi...\")\n",
        "\n",
        "        # Add your code here to use Imagen3 with the input values\n",
        "        # to generate and display the visual assets\n",
        "        image_list = generate_imagen_outputs(imagen_prompt, imagecount, aspectratio, model)\n",
        "\n",
        "        # Save in temp folder\n",
        "        image_file_dir= os.path.join(LOCAL_TEMP_DIR, selected_visual_segment)\n",
        "        print(f\"Retrieved {len(image_list)} images to be saved in in image_file_dir - {image_file_dir}\")\n",
        "\n",
        "        if os.path.exists(image_file_dir):\n",
        "            shutil.rmtree(image_file_dir)  # Delete the existing directory and its contents\n",
        "        os.makedirs(image_file_dir)  # Recreate the directory\n",
        "\n",
        "        # Convert GeneratedImage object\n",
        "        processed_images = []\n",
        "        image_count = 1\n",
        "        for generated_image in image_list:\n",
        "            generated_image_data = base64.b64decode(generated_image._as_base64_string())\n",
        "            pil_image = Image.open(io.BytesIO(generated_image_data))\n",
        "            pil_file = os.path.join(image_file_dir, generate_image_filename(selected_visual_segment, image_count))\n",
        "            pil_image.save(os.path.join(pil_file), \"PNG\")\n",
        "            print(f\"Saved image {image_count} @ {pil_file}\")\n",
        "            processed_images.append(pil_image)  # Add the PIL Image to the list\n",
        "            image_count += 1\n",
        "\n",
        "        yield processed_images, gr.update(value=\"Click to use Imagen3 to Generate Visual Assets\", interactive=True)  # Reset the button\n",
        "\n",
        "    def move_images_to_library(subject_input, age_input, clothing_input, theme_input, background_input, photography_input):\n",
        "\n",
        "      try:\n",
        "        source_folder = os.path.join(LOCAL_TEMP_DIR, selected_visual_segment)\n",
        "        destination_folder = os.path.join(LOCAL_INPUT_DIR_ACTOR, selected_visual_segment)\n",
        "        print(f\"Move Images to Library - Source {source_folder}, Target {destination_folder}!\")\n",
        "\n",
        "        # Check if the destination folder exists\n",
        "        if os.path.exists(destination_folder):\n",
        "            # Loop through all files and subdirectories in the source folder\n",
        "            for item in os.listdir(source_folder):\n",
        "                s = os.path.join(source_folder, item)\n",
        "                d = os.path.join(destination_folder, item)\n",
        "\n",
        "                # If the item is a file, move it\n",
        "                if os.path.isfile(s):\n",
        "                    shutil.move(s, d)\n",
        "                    print(f\"Moving asset from {s} to {d}\")\n",
        "                # If the item is a directory, use shutil.move for the whole subdirectory\n",
        "                elif os.path.isdir(s):\n",
        "                    shutil.move(s, d)\n",
        "\n",
        "            # Remove the source folder (now empty)\n",
        "            shutil.rmtree(source_folder)\n",
        "            print(f\"Files moved and source folder '{source_folder}' deleted.\")\n",
        "        else:\n",
        "            # If the destination doesn't exist, simply move the whole source folder\n",
        "            shutil.move(source_folder, destination_folder)\n",
        "            print(f\"Images moved to Marketing Library successfully into {destination_folder}!\")\n",
        "\n",
        "        updated_visualsegment_config = {\n",
        "          \"visualsegment\": selected_visual_segment,\n",
        "          \"subject\": subject_input,\n",
        "          \"age\": age_input,\n",
        "          \"clothing\": clothing_input,\n",
        "          \"theme\" : theme_input,\n",
        "          \"background\": background_input,\n",
        "          \"photography\": photography_input\n",
        "        }\n",
        "\n",
        "        # Update Firebase config\n",
        "        add_or_update_visual_segment(updated_visualsegment_config)\n",
        "\n",
        "        print(f\"Updated config - \\n {updated_visualsegment_config}\")\n",
        "\n",
        "        global visual_segment_options  # Declare visual_segment_options as global\n",
        "        visual_segment_options = get_visual_segments_list()\n",
        "\n",
        "        return\n",
        "\n",
        "      except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return gr.Error(f\"An error occurred: {e}\", duration=5)\n",
        "\n",
        "    # Event listener for the \"Load Config\" button\n",
        "    load_button.click(\n",
        "        load_config, inputs=visual_segment_dropdown, outputs=[subject_input, age_input, clothing_input, theme_input, background_input, photography_input, count_input, aspectratio_input, model_input]\n",
        "    ).then(\n",
        "      fn=lambda: [\n",
        "          gr.update(visible=True),  # Return the update directly\n",
        "          gr.update(visible=False),  # Return the update to disable image gallery\n",
        "          gr.update(visible=False),  # Return the update to disable approve button\n",
        "      ],\n",
        "      outputs=[generate_visual_assets, review_visual_assets, approve_visual_assets]\n",
        "    )\n",
        "\n",
        "    # Event listener for the dropdown\n",
        "    visual_segment_dropdown.change(\n",
        "        load_config, inputs=visual_segment_dropdown, outputs=[subject_input, age_input, clothing_input, theme_input, background_input, photography_input, count_input, aspectratio_input, model_input]\n",
        "    ).then(\n",
        "      fn=lambda: [\n",
        "          gr.update(visible=True),  # Return the update directly\n",
        "          gr.update(visible=False),  # Return the update to disable image gallery\n",
        "          gr.update(visible=False),  # Return the update to disable approve button\n",
        "      ],\n",
        "      outputs=[generate_visual_assets, review_visual_assets, approve_visual_assets]\n",
        "    )\n",
        "\n",
        "    # Event listener for the \"Create Config\" button\n",
        "    create_button.click(\n",
        "        create_new_segment, inputs=new_segment_input, outputs=[subject_input, age_input, clothing_input, theme_input, background_input, photography_input, count_input, aspectratio_input, model_input]\n",
        "    ).then(\n",
        "      fn=lambda: [\n",
        "          gr.update(visible=True),  # Return the update directly\n",
        "          gr.update(visible=False),  # Return the update to disable image gallery\n",
        "          gr.update(visible=False),  # Return the update to disable approve button\n",
        "      ],\n",
        "      outputs=[generate_visual_assets, review_visual_assets, approve_visual_assets]\n",
        "    )\n",
        "\n",
        "    # Event listener for the \"Generate Visual Assets\" button\n",
        "    generate_assets_button.click(\n",
        "        generate_assets,\n",
        "        inputs=[subject_input, age_input, clothing_input, theme_input, background_input, photography_input, count_input, aspectratio_input, model_input],\n",
        "        outputs=[gallery, generate_assets_button]  # Include the button as an output\n",
        "    ).then(\n",
        "      fn=lambda: [\n",
        "          gr.update(visible=True),\n",
        "          gr.update(visible=True),\n",
        "          gr.update(value=f\"{imagen_prompt}\")\n",
        "      ],\n",
        "      outputs=[review_visual_assets, approve_visual_assets, prompt_text]\n",
        "    )\n",
        "\n",
        "    # Event listener for the \"Save Images to Marketing Library\" button\n",
        "    approve_button.click(\n",
        "        move_images_to_library, inputs=[subject_input, age_input, clothing_input, theme_input, background_input, photography_input], outputs = []\n",
        "    ) .then(\n",
        "      fn=lambda: [\n",
        "          gr.update(visible=False),\n",
        "          gr.update(visible=False),\n",
        "          gr.update(visible=False)\n",
        "      ],\n",
        "      outputs=[generate_visual_assets, review_visual_assets, approve_visual_assets]\n",
        "    ).then(\n",
        "      fn=lambda: [\n",
        "          gr.update(choices=get_visual_segments_list()),  # Update the dropdown options\n",
        "          gr.update(value=None),  # Reset the dropdown value\n",
        "          gr.update(value=None),\n",
        "          gr.update(value=None),\n",
        "          gr.update(value=None),\n",
        "          gr.update(value=None),\n",
        "          gr.update(value=default_background),\n",
        "          gr.update(value=default_photography),\n",
        "          gr.update(value=default_count),\n",
        "          gr.update(value=default_aspectratio),\n",
        "          gr.update(value=default_model)\n",
        "      ],\n",
        "      outputs=[visual_segment_dropdown, new_segment_input, subject_input, age_input, clothing_input, theme_input, background_input, photography_input, count_input, aspectratio_input, model_input]\n",
        "    )\n"
      ],
      "metadata": {
        "id": "J7KdfE2rbmI-",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730348250106,
          "user_tz": -480,
          "elapsed": 965,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f67e977-3a90-4088-aa27-3e1dfacd69d5"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ui_demo_tab_assetcreation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Gradio Front End - Demo Asset Preprocessing Tab\n",
        "\n",
        "gallery_dirname_list_pp = [] #global variable to track selected thumbnail directory to show full image\n",
        "\n",
        "# Function to get all image files in a directory\n",
        "def get_image_files_pp(directory):\n",
        "    image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp']\n",
        "    return [f for f in os.listdir(directory) if os.path.splitext(f)[1].lower() in image_extensions]\n",
        "\n",
        "# Function to create thumbnails\n",
        "def create_thumbnail_pp(image_path, size=(200, 200)):\n",
        "    with Image.open(image_path) as img:\n",
        "        img.thumbnail(size, Image.Resampling.LANCZOS)  # Use a high-quality resampling filter\n",
        "        return np.array(img)\n",
        "\n",
        "# Function to update thumbnails\n",
        "def update_thumbnails_pp(selected_folder):\n",
        "    image_files = get_image_files_pp(selected_folder)\n",
        "    thumbnails = [create_thumbnail_pp(os.path.join(selected_folder, img)) for img in image_files]\n",
        "    imagepath = [(os.path.join(selected_folder, img)) for img in image_files]\n",
        "    return thumbnails, imagepath\n",
        "\n",
        "# Function to display selected image\n",
        "def display_image_pp(evt: gr.SelectData): #, selected_folder):\n",
        "    print(f\"all_thumbnails positional data {gallery_dirname_list_pp[evt.index]}\")\n",
        "    return Image.open(gallery_dirname_list_pp[evt.index])\n",
        "\n",
        "def select_folder_pp(selected_files):\n",
        "    global gallery_dirname_list_pp  # Declare gallery_dirname_list_pp as global\n",
        "    print(f\"Selection - {selected_files}\")\n",
        "\n",
        "    if selected_files:\n",
        "        dirnames = []\n",
        "        for file_path in selected_files:\n",
        "            if os.path.isfile(file_path):\n",
        "                dirname = os.path.dirname(file_path)\n",
        "            else:\n",
        "                dirname = file_path\n",
        "            dirnames.append(dirname)\n",
        "\n",
        "        # Get unique dirnames\n",
        "        unique_dirnames = list(set(dirnames))\n",
        "\n",
        "        all_thumbnails = []\n",
        "        gallery_dirname_list_pp = []  # Reset gallery_dirname_list_pp\n",
        "        for dirname in unique_dirnames:\n",
        "            thumbnails, imagepath = update_thumbnails_pp(dirname)  # Get thumbnails for the current dirname\n",
        "            all_thumbnails.extend(thumbnails)\n",
        "            gallery_dirname_list_pp.extend(imagepath)  # Add imagepath for each thumbnail\n",
        "\n",
        "        return all_thumbnails, None  # Return only the list of thumbnails\n",
        "    return None, None  # Return None if no files are selected\n",
        "\n",
        "# Main Gradio interface\n",
        "with gr.Blocks() as ui_demo_tab_assetpreprocess:\n",
        "\n",
        "    print(\"Inui_demo_tab_assetpreprocess\")\n",
        "\n",
        "    ROOT_FOLDER = LOCAL_OUTPUT_DIR\n",
        "\n",
        "    with gr.Column(variant='panel'):\n",
        "      gr.Markdown(\"# Marketing Assets Preprocessing\")\n",
        "\n",
        "    with gr.Column(variant='panel'):\n",
        "      preprocess_assets_button = gr.Button(\"Click to Preprocess Newly Created Visual Assets\")\n",
        "\n",
        "    with gr.Column(variant='panel'):\n",
        "      with gr.Row():\n",
        "          with gr.Column(scale=1):\n",
        "              file_explorer_pp = gr.FileExplorer(root_dir=ROOT_FOLDER, ignore_glob=\"*.json\", label=\"Library Explorer\")\n",
        "\n",
        "          with gr.Column(scale=3):\n",
        "              thumbnail_gallery_pp = gr.Gallery(label=\"Selected Image Gallery\", columns=3, rows=None, height=\"auto\")\n",
        "\n",
        "    with gr.Column(variant='panel'):\n",
        "      with gr.Row():\n",
        "          displayed_image_pp = gr.Image(label=\"Selected Image\")\n",
        "\n",
        "    def preprocess_assets_in_library(progress=gr.Progress()):\n",
        "      progress(0.1, desc=\"Step 1: Checking for unprocessed assets...\")\n",
        "\n",
        "      list_input_files = get_filepath_in_folder_nested(os.path.join(LOCAL_INPUT_DIR_ARTEFACTS, \"Actors\"))\n",
        "      unprocessed_input_files = []\n",
        "      for input_path in list_input_files:\n",
        "        input_file = os.path.basename(input_path)\n",
        "        output_path = os.path.join(LOCAL_OUTPUT_DIR_ACTOR, f\"NoBg_{input_file}\")\n",
        "        if os.path.exists(output_path):\n",
        "          print(f\"The file {output_path} exists.\")\n",
        "        else:\n",
        "          print(f\"The file {output_path} does not exist.\")\n",
        "          unprocessed_input_files.append(input_path)\n",
        "\n",
        "      count_unprocessed = len(unprocessed_input_files)\n",
        "      count_processed = 1\n",
        "      for input_path in unprocessed_input_files:\n",
        "        progress(round((count_processed / count_unprocessed) * 0.8, 2), desc=\"Step 2: Processing unprocessed assets...\")\n",
        "        input_file = os.path.basename(input_path)\n",
        "        output_path = os.path.join(LOCAL_OUTPUT_DIR_ACTOR, f\"NoBg_{input_file}\")\n",
        "        mask_path = os.path.join(LOCAL_OUTPUT_DIR_ACTOR, f\"Mask_{input_file}\")\n",
        "        remove_background(input_path, output_path, mask_path)\n",
        "        count_processed += 1\n",
        "\n",
        "      progress(0.95, desc=\"Step 3: Almost done...\")\n",
        "\n",
        "      return gr.update(root_dir=ROOT_FOLDER, ignore_glob=\"*.json\", label=\"Library Explorer\"), gr.update(label=\"Selected Image Gallery\", columns=3, rows=None, height=\"auto\"), None\n",
        "\n",
        "    # Event listener for the \"Save Images to Marketing Library\" button\n",
        "    preprocess_assets_button.click(\n",
        "        preprocess_assets_in_library, inputs=[], outputs = [file_explorer_pp, thumbnail_gallery_pp, displayed_image_pp]\n",
        "    )\n",
        "\n",
        "    # Event handler for folder selection\n",
        "    file_explorer_pp.change(\n",
        "        select_folder_pp,\n",
        "        inputs=[file_explorer_pp],\n",
        "        outputs=[thumbnail_gallery_pp, displayed_image_pp]\n",
        "    )\n",
        "\n",
        "    # Event handler for thumbnail selection\n",
        "    thumbnail_gallery_pp.select(\n",
        "        display_image_pp,\n",
        "        inputs=[],\n",
        "        outputs=[displayed_image_pp]\n",
        "    )"
      ],
      "metadata": {
        "id": "xaQMAsC90pga",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730348250285,
          "user_tz": -480,
          "elapsed": 181,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dece204-322b-472e-a197-e736c19fcf14"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inui_demo_tab_assetpreprocess\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Gradio Front End - Demo Banner Template Element Configuration\n",
        "\n",
        "import gradio as gr\n",
        "from gradio_image_annotation import image_annotator\n",
        "import json\n",
        "\n",
        "import os\n",
        "\n",
        "# Example usage\n",
        "image_data = create_file_map(LOCAL_OUTPUT_DIR_BG, \".png\", \"Grid_\")\n",
        "\n",
        "# Define a dictionary to hold labels and their corresponding colors\n",
        "label_color_map = {\n",
        "    \"logo_position\": (66, 133, 244),\n",
        "    \"graphic1_position\": (24, 90, 188),\n",
        "    \"graphic2_position\": (24, 90, 188),\n",
        "    \"actor_position\": (52, 168, 83),\n",
        "    \"text_header1_position\": (60, 64, 67),\n",
        "    \"text_header2_position\": (60, 64, 67),\n",
        "    \"text_details_position\": (95, 99, 104),\n",
        "    \"text_highlight1_position\": (32, 33, 36),\n",
        "    \"graphic_highlight2_position\": (24, 90, 188),\n",
        "    \"text_highlight3_position\": (32, 33, 36),\n",
        "    \"text_tagline_position\": (128, 134, 139),\n",
        "    \"text_action_position\": (251, 188, 4)\n",
        "}\n",
        "\n",
        "# Initialize empty lists for labels and colors\n",
        "label_list = []\n",
        "label_colors = []\n",
        "\n",
        "# Loop through the dictionary to populate the lists\n",
        "for label, color in label_color_map.items():\n",
        "    label_list.append(label)\n",
        "    label_colors.append(color)\n",
        "\n",
        "def get_image_location(image_key):\n",
        "  return image_data.get(image_key)\n",
        "\n",
        "def get_template_configuration(template_name):\n",
        "\n",
        "  existing_config = get_bannertemplate_config(template_name)\n",
        "\n",
        "  # Remove the bannertemplate key\n",
        "  del existing_config['bannertemplate']\n",
        "\n",
        "  output_list = []\n",
        "\n",
        "  for label, position_data in existing_config.items():\n",
        "    if label != 'background_size':\n",
        "      x = position_data['x']\n",
        "      y = position_data['y']\n",
        "      width = position_data['width']\n",
        "      height = position_data['height']\n",
        "\n",
        "      xmax = x + width\n",
        "      ymax = y + height\n",
        "\n",
        "      # Retrieve the color from the color map using the label\n",
        "      color = label_color_map.get(label, (255, 255, 255))  # Default to black if label not found\n",
        "\n",
        "      output_dict = {\n",
        "        'label': label,\n",
        "        'xmin': x,\n",
        "        'ymin': y,\n",
        "        'xmax': xmax,\n",
        "        'ymax': ymax,\n",
        "        'color': color\n",
        "      }\n",
        "\n",
        "      output_list.append(output_dict)\n",
        "\n",
        "  return output_list\n",
        "\n",
        "def on_image_key_select(template_name):\n",
        "\n",
        "  annotator = image_annotator(\n",
        "          value={\"image\" : image_data.get(template_name), \"boxes\": get_template_configuration(template_name)},\n",
        "          label_list=label_list,\n",
        "          label_colors=label_colors,\n",
        "      )\n",
        "  return annotator\n",
        "\n",
        "def save_template_configuration(annotations, template_name):\n",
        "    result = {}\n",
        "\n",
        "    result = get_bannertemplate_config(template_name)\n",
        "\n",
        "    # Add bannertemplate element back\n",
        "    result[\"bannertemplate\"] = template_name\n",
        "\n",
        "    elements = annotations[\"boxes\"]\n",
        "    for element in elements:\n",
        "        label = element[\"label\"]\n",
        "        result[label] = {\n",
        "            \"x\": element[\"xmin\"],\n",
        "            \"y\": element[\"ymin\"],\n",
        "            \"width\": element[\"xmax\"] - element[\"xmin\"],\n",
        "            \"height\": element[\"ymax\"] - element[\"ymin\"]\n",
        "        }\n",
        "\n",
        "    add_or_update_bannertemplate(result)\n",
        "\n",
        "    print(f\"Banner template configuration for {image_key_dropdown} saved...\")\n",
        "\n",
        "    return result\n",
        "\n",
        "with gr.Blocks() as ui_demo_bannertemplateconfig_tab:\n",
        "\n",
        "  print(\"In ui_demo_bannertemplateconfig_tab\")\n",
        "\n",
        "  # Title and description using gr.Markdown (within gr.Blocks context)\n",
        "  gr.Markdown(\"# Banner Template Configuration Demo\")\n",
        "\n",
        "  gr.Markdown(\"#### Select Banner Template\")\n",
        "  image_key_dropdown = gr.Dropdown(choices=list(image_data.keys()), label=\"Select the background template to configure\")\n",
        "\n",
        "  with gr.Tab(\"Object annotation\", id=\"tab_object_annotation\"):\n",
        "      annotator = image_annotator(\n",
        "          value=None,\n",
        "          show_label=False\n",
        "      )\n",
        "\n",
        "      button_get = gr.Button(\"Save Template Configuration\")\n",
        "      json_boxes = gr.JSON()\n",
        "      button_get.click(save_template_configuration, (annotator, image_key_dropdown), json_boxes)\n",
        "\n",
        "  # Event handling\n",
        "  image_key_dropdown.change(\n",
        "      on_image_key_select,\n",
        "      inputs=[image_key_dropdown],\n",
        "      outputs=annotator,\n",
        "  )"
      ],
      "metadata": {
        "id": "_d2kRWOYpLfA",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730348250467,
          "user_tz": -480,
          "elapsed": 184,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4ab22d7-c800-4bc9-e6c2-d6cb4e7bc4f7"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In ui_demo_bannertemplateconfig_tab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Gradio Front End - Generate Dynamically New Marketing Banners\n",
        "\n",
        "selected_visual_segment_list = None\n",
        "selected_bannertemplate_list = None\n",
        "\n",
        "def generate_banner_filename(visual_segment, image_count):\n",
        "  now = datetime.datetime.now()\n",
        "  datetime_str = now.strftime(\"%d%m%H%M%S\")  # Format as ddmmHHMMSS\n",
        "  filename = f\"{visual_segment}_{image_count}_{datetime_str}.png\"  # Create filename with .png extension\n",
        "  return filename\n",
        "\n",
        "def display_message_bg(type, msg, duration):\n",
        "    duration = None if duration < 0 else duration\n",
        "    if type == \"error\":\n",
        "        raise gr.Error(msg, duration=duration)\n",
        "    elif type == \"info\":\n",
        "        gr.Info(msg, duration=duration)\n",
        "    elif type == \"warning\":\n",
        "        gr.Warning(msg,  duration=duration)\n",
        "\n",
        "with gr.Blocks() as ui_demo_tab_bannergen:\n",
        "\n",
        "    print(\"In ui_demo_tab_bannergen\")\n",
        "\n",
        "    with gr.Row(variant='panel'):\n",
        "      gr.Markdown(\"# Generate Dynamically New Marketing Banners\")\n",
        "\n",
        "    with gr.Column(variant='panel'):\n",
        "      preprocess_visualsegments_button = gr.Button(\"Click to update Newly Added Visual Segments\")\n",
        "\n",
        "    with gr.Row():\n",
        "      with gr.Column(scale=1, variant='panel'):\n",
        "        visual_segment_dropdown = gr.Dropdown(choices=get_visual_segments_list(), label=\"Select Visual Segment\", multiselect=True)\n",
        "\n",
        "      with gr.Column(scale=1, variant='panel'):\n",
        "        bannertemplate_options = get_bannertemplate_list()\n",
        "        bannertemplate_dropdown = gr.Dropdown(choices=bannertemplate_options, label=\"Select Banner Template\", multiselect=True)\n",
        "\n",
        "    with gr.Column(variant='panel'):\n",
        "      with gr.Row():\n",
        "          text_header1_input = gr.Textbox(label=\"Text Header 1\", value = \"Freedom Unlimited Apps Bundle Special Offer\", lines = 2, interactive=True)\n",
        "          text_header2_input = gr.Textbox(label=\"Text Header 2\", value = \"Enjoy the festivities with new exciting games and movies.\", lines = 2, interactive=True)\n",
        "      with gr.Row():\n",
        "          text_details_input = gr.Textbox(label=\"Text Details\", value = \"FREEDOM U ! Now Able to Access More Apps, Limitless Call to IM3 Ooredoo and Tri! Plus, 24 hours to access even more of your favorite apps, like YouTube, Instagram, TikTok, Facebook, Spotify, Joox, WhatsApp, and Line. This will be unlimited\", lines = 5, interactive=True)\n",
        "      with gr.Row():\n",
        "          text_highlight1_input = gr.Textbox(label=\"Text Highlight 1\", value = \"100 GB\", interactive=True)\n",
        "          text_highlight3_input = gr.Textbox(label=\"Text Highlight 3\", value = \"250 Ribu Only\", interactive=True)\n",
        "      with gr.Row():\n",
        "          text_tagline_input = gr.Textbox(label=\"Text Tagline\", value = \"Offer Valid for prepaid and postpaid IM3 customers.\", interactive=True)\n",
        "          text_action_input = gr.Textbox(label=\"Text Action\", value = \"BUY NOW\", interactive=True)\n",
        "\n",
        "      with gr.Row():\n",
        "        with gr.Column(scale=1, variant='panel'):\n",
        "          logo_path_input = gr.Textbox(label=\"Logo Path\", value = \"ctellogo.png\", interactive=True)\n",
        "\n",
        "      with gr.Row():\n",
        "        with gr.Column(scale=1, variant='panel'):\n",
        "          graphic1_path_input = gr.Textbox(label=\"Graphics 1\", value = \"Graphics1.png\", interactive=True)\n",
        "        with gr.Column(scale=1, variant='panel'):\n",
        "          graphic2_path_input = gr.Textbox(label=\"Graphics 2\", value = \"Graphics4.png\", interactive=True)\n",
        "        with gr.Column(scale=1, variant='panel'):\n",
        "          graphic_highlight2_path_input = gr.Textbox(label=\"Graphics Highlight\", value = \"50GraphicH2.png\", interactive=True)\n",
        "\n",
        "    with gr.Row(visible=False) as generate_banner_assets:\n",
        "      generate_bannerassets_button = gr.Button(\"Click to Generate Banners for Campaign\")\n",
        "\n",
        "    with gr.Row(visible=False) as review_banner_assets:\n",
        "      with gr.Row(variant='panel'):\n",
        "        banner_gallery = gr.Gallery(\n",
        "          label=\"Generated Images\",\n",
        "          columns=[3],\n",
        "          height=\"auto\"\n",
        "        )\n",
        "\n",
        "    with gr.Row(visible=False) as success_banner_assets:\n",
        "      with gr.Row(variant='panel'):\n",
        "        banner_prompt_text = gr.Markdown()\n",
        "\n",
        "    def load_config(selected_visual_segments, selected_bannertemplates):\n",
        "\n",
        "      if not selected_visual_segments:\n",
        "          gr.Warning(\"Please select one or more visual segment from the dropdown.\", duration=2)\n",
        "          return\n",
        "\n",
        "      if not selected_bannertemplates:\n",
        "          gr.Warning(\"Please select one or more banner templates from the dropdown.\", duration=2)\n",
        "          return\n",
        "\n",
        "      global selected_visual_segment_list  # Declare selected_visual_segment as global\n",
        "      selected_visual_segment_list = selected_visual_segments\n",
        "\n",
        "      global selected_bannertemplate_list\n",
        "      selected_bannertemplate_list = selected_bannertemplates\n",
        "\n",
        "      print(f\"Selected Visual Segment - {selected_visual_segment_list}; Banner Templates - {selected_bannertemplate_list}\")\n",
        "\n",
        "      return\n",
        "\n",
        "    # Function to handle \"Generate Banner Assets\" button click\n",
        "    def generate_assets(\n",
        "          visual_segment_dropdown,\n",
        "          bannertemplate_dropdown,\n",
        "          text_header1_input,\n",
        "          text_header2_input,\n",
        "          text_details_input,\n",
        "          text_highlight1_input,\n",
        "          text_highlight3_input,\n",
        "          text_tagline_input,\n",
        "          text_action_input,\n",
        "          logo_path_input,\n",
        "          graphic1_path_input,\n",
        "          graphic2_path_input,\n",
        "          graphic_highlight2_path_input,\n",
        "          progress=gr.Progress()):\n",
        "\n",
        "        # Show a \"processing\" state while generating images\n",
        "        yield [], gr.update(value=\"Processing...\", interactive=False)  # Update the button\n",
        "\n",
        "        print(f\"\"\"\n",
        "          {visual_segment_dropdown},\n",
        "          {bannertemplate_dropdown},\n",
        "          {text_header1_input},\n",
        "          {text_header2_input},\n",
        "          {text_details_input},\n",
        "          {text_highlight1_input},\n",
        "          {text_highlight3_input},\n",
        "          {text_tagline_input},\n",
        "          {text_action_input},\n",
        "          {logo_path_input},\n",
        "          {graphic1_path_input},\n",
        "          {graphic2_path_input},\n",
        "          {graphic_highlight2_path_input}\"\"\")\n",
        "\n",
        "        image_inputs = {}\n",
        "\n",
        "        if graphic1_path_input is not None and graphic1_path_input.strip() != \"\":\n",
        "          image_inputs['graphic1_path'] = f\"{LOCAL_INPUT_DIR_GRAPHICS}/{graphic1_path_input}\"\n",
        "\n",
        "        if graphic2_path_input is not None and graphic2_path_input.strip() != \"\":\n",
        "          image_inputs['graphic2_path'] = f\"{LOCAL_INPUT_DIR_GRAPHICS}/{graphic2_path_input}\"\n",
        "\n",
        "        if graphic_highlight2_path_input is not None and graphic_highlight2_path_input.strip() != \"\":\n",
        "          image_inputs['graphic_highlight2_path'] = f\"{LOCAL_INPUT_DIR_GRAPHICS}/{graphic_highlight2_path_input}\"\n",
        "\n",
        "        if logo_path_input is not None and logo_path_input.strip() != \"\":\n",
        "          image_inputs['logo_path'] = f\"{LOCAL_INPUT_DIR_LOGO}/{logo_path_input}\"\n",
        "\n",
        "        text_inputs = {}\n",
        "\n",
        "        if text_header1_input is not None and text_header1_input.strip() != \"\":\n",
        "          text_inputs['text_header1'] = text_header1_input\n",
        "\n",
        "        if text_header2_input is not None and text_header2_input.strip() != \"\":\n",
        "          text_inputs['text_header2'] = text_header2_input\n",
        "\n",
        "        if text_details_input is not None and text_details_input.strip() != \"\":\n",
        "          text_inputs['text_details'] = text_details_input\n",
        "\n",
        "        if text_highlight1_input is not None and text_highlight1_input.strip() != \"\":\n",
        "          text_inputs['text_highlight1'] = text_highlight1_input\n",
        "\n",
        "        if text_highlight3_input is not None and text_highlight3_input.strip() != \"\":\n",
        "          text_inputs['text_highlight3'] = text_highlight3_input\n",
        "\n",
        "        if text_tagline_input is not None and text_tagline_input.strip() != \"\":\n",
        "          text_inputs['text_tagline'] = text_tagline_input\n",
        "\n",
        "        if text_action_input is not None and text_action_input.strip() != \"\":\n",
        "          text_inputs['text_action'] = text_action_input\n",
        "\n",
        "        bannertemplate_list = bannertemplate_dropdown\n",
        "        visual_segments_list = visual_segment_dropdown\n",
        "\n",
        "        progress(0.1, desc=\"Step 1: Checking banner configuration and assets...\")\n",
        "\n",
        "        total_banner_count = 0\n",
        "        for bannertemplate in bannertemplate_list:\n",
        "          for visual_segment in visual_segments_list:\n",
        "            for image_input in (find_files_with_prefix(LOCAL_OUTPUT_DIR_ACTOR, f\"NoBg_{visual_segment}\")):\n",
        "              total_banner_count += 1\n",
        "\n",
        "        generated_banner_images = []\n",
        "        current_banner_count = 0\n",
        "        for bannertemplate in bannertemplate_list:\n",
        "          background_path = f\"{LOCAL_INPUT_DIR_BG}/{bannertemplate}.png\"\n",
        "          background_config = get_bannertemplate_config(bannertemplate)\n",
        "          for visual_segment in visual_segments_list:\n",
        "            for image_input in (find_files_with_prefix(LOCAL_OUTPUT_DIR_ACTOR, f\"NoBg_{visual_segment}\")):\n",
        "              current_banner_count += 1\n",
        "              progress(round((current_banner_count / total_banner_count) * 0.9, 2), desc=\"Step 2: Generating banners dynamically ...\")\n",
        "              image_inputs['actor_path'] = image_input\n",
        "              output_filename = generate_banner_filename(visual_segment, current_banner_count)\n",
        "              output_path = f\"{LOCAL_OUTPUT_DIR_BANNER}/{output_filename}\"\n",
        "              print(f\"Generating banner count {current_banner_count} of {total_banner_count}... {output_path}\")\n",
        "              # Create the banner with Actor & Logo overlaid\n",
        "              generated_banner_image = create_marketing_banner_baseline(background_path, background_config, image_inputs, text_inputs, output_path)\n",
        "              print(f\"Generated banner count {current_banner_count} of {total_banner_count}... {output_path}\")\n",
        "              generated_banner_images.append(generated_banner_image)\n",
        "\n",
        "        progress(0.95, desc=\"Step 3: Almost done...\")\n",
        "\n",
        "        yield generated_banner_images, gr.update(value=\"Click to Generate Banners for Campaign\", interactive=True)  # Reset the button\n",
        "\n",
        "    # Event listener for the dropdown\n",
        "    visual_segment_dropdown.change(\n",
        "        load_config, inputs=[visual_segment_dropdown, bannertemplate_dropdown], outputs=[]\n",
        "    ).then(\n",
        "      fn=lambda: [\n",
        "          gr.update(visible=True),  # Return the update directly\n",
        "          gr.update(visible=False)  # Return the update to disable image gallery\n",
        "      ],\n",
        "      outputs=[generate_banner_assets, review_banner_assets]\n",
        "    )\n",
        "\n",
        "    # Event listener for the dropdown\n",
        "    bannertemplate_dropdown.change(\n",
        "        load_config, inputs=[visual_segment_dropdown, bannertemplate_dropdown], outputs=[]\n",
        "    ).then(\n",
        "      fn=lambda: [\n",
        "          gr.update(visible=True),  # Return the update directly\n",
        "          gr.update(visible=False)  # Return the update to disable image gallery\n",
        "      ],\n",
        "      outputs=[generate_banner_assets, review_banner_assets]\n",
        "    )\n",
        "\n",
        "    # Event listener for the \"Generate Visual Assets\" button\n",
        "    generate_bannerassets_button.click(\n",
        "      fn=lambda: gr.update(visible=True),\n",
        "      outputs=review_banner_assets\n",
        "    ).then(\n",
        "        generate_assets,\n",
        "        inputs=[\n",
        "          visual_segment_dropdown,\n",
        "          bannertemplate_dropdown,\n",
        "          text_header1_input,\n",
        "          text_header2_input,\n",
        "          text_details_input,\n",
        "          text_highlight1_input,\n",
        "          text_highlight3_input,\n",
        "          text_tagline_input,\n",
        "          text_action_input,\n",
        "          logo_path_input,\n",
        "          graphic1_path_input,\n",
        "          graphic2_path_input,\n",
        "          graphic_highlight2_path_input\n",
        "        ],\n",
        "        outputs=[banner_gallery, generate_bannerassets_button]  # Include the button as an output\n",
        "    ).then(\n",
        "      fn=lambda: [\n",
        "          gr.update(visible=True),\n",
        "          gr.update(value=f\"##  ... Banner Generation Demo Complete. Powered By Google Vertex AI, Gemini & Imagen3 ...\")\n",
        "      ],\n",
        "      outputs=[success_banner_assets, banner_prompt_text]\n",
        "    )\n",
        "\n",
        "    def update_dropdown():  # No input needed here\n",
        "        \"\"\"\n",
        "        This function updates the choices of the visual_segment_dropdown.\n",
        "        \"\"\"\n",
        "        return gr.Dropdown(choices=get_visual_segments_list(), label=\"Select Visual Segment\", multiselect=True)\n",
        "\n",
        "    preprocess_visualsegments_button.click(\n",
        "        fn=update_dropdown,\n",
        "        outputs=visual_segment_dropdown\n",
        "    )"
      ],
      "metadata": {
        "id": "b1u99tyg6Y5v",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730348252073,
          "user_tz": -480,
          "elapsed": 1608,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc53fafc-3820-4215-c74d-d3edd1515e25"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In ui_demo_tab_bannergen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Gradio Front End Launch Main\n",
        "\n",
        "# @title Gradio Front End General Configuration\n",
        "\n",
        "print(f\"Gradio version: {gr.__version__}\")\n",
        "\n",
        "css_styling=\"\"\"\n",
        "    #flag-button {\n",
        "        display: none !important;\n",
        "    }\n",
        "    footer {\n",
        "        visibility: hidden;\n",
        "    }\n",
        "    .gradio-container h1, /* Style h1 elements */\n",
        "    .gradio-container .gr-text h1 { /* Also style h1 within .gr-text containers */\n",
        "        text-align: center;\n",
        "    }\n",
        "\"\"\"\n",
        "\n",
        "theme_styling = gr.themes.Soft(\n",
        "    text_size=gr.themes.Size(xxs=\"10px\", xs=\"12px\", sm=\"14px\", md=\"18px\", lg=\"22px\", xl=\"24px\", xxl=\"28px\"),\n",
        "    font=['Quicksand', gr.themes.GoogleFont('ui-sans-serif'), 'system-ui', 'sans-serif'],\n",
        "    font_mono=['IBM Plex Mono', 'ui-monospace', 'Consolas', gr.themes.GoogleFont('monospace')],\n",
        ").set(\n",
        "    prose_text_size='*text_lg',\n",
        "    prose_header_text_weight='700'\n",
        ")\n",
        "\n",
        "visual_segment_options = get_visual_segments_list()\n",
        "\n",
        "demo = gr.TabbedInterface(\n",
        "    [ui_about_tab, ui_demo_tab_assetlibrary, ui_demo_tab_assetcreation, ui_demo_tab_assetpreprocess, ui_demo_bannertemplateconfig_tab, ui_demo_tab_bannergen],\n",
        "    [\"About\", \"Demo Asset Library\", \"Demo Asset Creation\", \"Demo Asset Preprocessing\", \"Demo Banner Template\", \"Demo Banner Generation\"],\n",
        "    theme=theme_styling,\n",
        "    css=css_styling\n",
        ")\n",
        "\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "id": "MCFBkvrSmgIC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "294445d7-4848-4b72-b2c3-22a5e62b2e11",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1730348461719,
          "user_tz": -480,
          "elapsed": 209648,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradio version: 4.44.1\n",
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://436fb404437a1c8dcc.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://436fb404437a1c8dcc.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Visual Segment - ['Test2']; Banner Templates - ['Template1']\n",
            "\n",
            "          ['Test2'],\n",
            "          ['Template1'],\n",
            "          ,\n",
            "          ,\n",
            "          ,\n",
            "          ,\n",
            "          ,\n",
            "          ,\n",
            "          ,\n",
            "          ,\n",
            "          ,\n",
            "          ,\n",
            "          \n",
            "Generating banner count 1 of 3... /content/demo/output/Banner_Processed/Test2_1_3110041845.png\n",
            "Original size of overlay image /content/demo/output/Actors_Processed/NoBg_Test2_2_3110032005.png, Aspect Ratio - 0.9787946428571429, Size - (1920, 1080)\n",
            "Resized overlay image to Size - (1009, 1031)\n",
            "Width exceeds boundary, adjusting overlay image with width / height - 775 / 791 to Size - (775, 791)\n",
            "Generated banner count 1 of 3... /content/demo/output/Banner_Processed/Test2_1_3110041845.png\n",
            "Generating banner count 2 of 3... /content/demo/output/Banner_Processed/Test2_2_3110041846.png\n",
            "Original size of overlay image /content/demo/output/Actors_Processed/NoBg_Test2_3_3110032006.png, Aspect Ratio - 1.0751708428246014, Size - (1920, 1080)\n",
            "Resized overlay image to Size - (1108, 1031)\n",
            "Width exceeds boundary, adjusting overlay image with width / height - 775 / 720 to Size - (775, 720)\n",
            "Generated banner count 2 of 3... /content/demo/output/Banner_Processed/Test2_2_3110041846.png\n",
            "Generating banner count 3 of 3... /content/demo/output/Banner_Processed/Test2_3_3110041846.png\n",
            "Original size of overlay image /content/demo/output/Actors_Processed/NoBg_Test2_1_3110032004.png, Aspect Ratio - 1.0669642857142858, Size - (1920, 1080)\n",
            "Resized overlay image to Size - (1100, 1031)\n",
            "Width exceeds boundary, adjusting overlay image with width / height - 775 / 726 to Size - (775, 726)\n",
            "Generated banner count 3 of 3... /content/demo/output/Banner_Processed/Test2_3_3110041846.png\n",
            "\n",
            "          ['Test2'],\n",
            "          ['Template1'],\n",
            "          Party. Party. Party,\n",
            "          ,\n",
            "          ,\n",
            "          ,\n",
            "          ,\n",
            "          ,\n",
            "          ,\n",
            "          ,\n",
            "          ,\n",
            "          ,\n",
            "          \n",
            "Generating banner count 1 of 3... /content/demo/output/Banner_Processed/Test2_1_3110041910.png\n",
            "Original size of overlay image /content/demo/output/Actors_Processed/NoBg_Test2_2_3110032005.png, Aspect Ratio - 0.9787946428571429, Size - (1920, 1080)\n",
            "Resized overlay image to Size - (1009, 1031)\n",
            "Width exceeds boundary, adjusting overlay image with width / height - 775 / 791 to Size - (775, 791)\n",
            "Generated banner count 1 of 3... /content/demo/output/Banner_Processed/Test2_1_3110041910.png\n",
            "Generating banner count 2 of 3... /content/demo/output/Banner_Processed/Test2_2_3110041912.png\n",
            "Original size of overlay image /content/demo/output/Actors_Processed/NoBg_Test2_3_3110032006.png, Aspect Ratio - 1.0751708428246014, Size - (1920, 1080)\n",
            "Resized overlay image to Size - (1108, 1031)\n",
            "Width exceeds boundary, adjusting overlay image with width / height - 775 / 720 to Size - (775, 720)\n",
            "Generated banner count 2 of 3... /content/demo/output/Banner_Processed/Test2_2_3110041912.png\n",
            "Generating banner count 3 of 3... /content/demo/output/Banner_Processed/Test2_3_3110041913.png\n",
            "Original size of overlay image /content/demo/output/Actors_Processed/NoBg_Test2_1_3110032004.png, Aspect Ratio - 1.0669642857142858, Size - (1920, 1080)\n",
            "Resized overlay image to Size - (1100, 1031)\n",
            "Width exceeds boundary, adjusting overlay image with width / height - 775 / 726 to Size - (775, 726)\n",
            "Generated banner count 3 of 3... /content/demo/output/Banner_Processed/Test2_3_3110041913.png\n",
            "\n",
            "          ['Test2'],\n",
            "          ['Template1'],\n",
            "          Party. Party. Party,\n",
            "          ,\n",
            "          Party unlimited at Blore for this new year, we promise so much fun as we head into 2025. Its gonna be awesome......,\n",
            "          ,\n",
            "          ,\n",
            "          ,\n",
            "          ,\n",
            "          ,\n",
            "          ,\n",
            "          ,\n",
            "          \n",
            "Generating banner count 1 of 3... /content/demo/output/Banner_Processed/Test2_1_3110041933.png\n",
            "Original size of overlay image /content/demo/output/Actors_Processed/NoBg_Test2_2_3110032005.png, Aspect Ratio - 0.9787946428571429, Size - (1920, 1080)\n",
            "Resized overlay image to Size - (1009, 1031)\n",
            "Width exceeds boundary, adjusting overlay image with width / height - 775 / 791 to Size - (775, 791)\n",
            "Generated banner count 1 of 3... /content/demo/output/Banner_Processed/Test2_1_3110041933.png\n",
            "Generating banner count 2 of 3... /content/demo/output/Banner_Processed/Test2_2_3110041935.png\n",
            "Original size of overlay image /content/demo/output/Actors_Processed/NoBg_Test2_3_3110032006.png, Aspect Ratio - 1.0751708428246014, Size - (1920, 1080)\n",
            "Resized overlay image to Size - (1108, 1031)\n",
            "Width exceeds boundary, adjusting overlay image with width / height - 775 / 720 to Size - (775, 720)\n",
            "Generated banner count 2 of 3... /content/demo/output/Banner_Processed/Test2_2_3110041935.png\n",
            "Generating banner count 3 of 3... /content/demo/output/Banner_Processed/Test2_3_3110041937.png\n",
            "Original size of overlay image /content/demo/output/Actors_Processed/NoBg_Test2_1_3110032004.png, Aspect Ratio - 1.0669642857142858, Size - (1920, 1080)\n",
            "Resized overlay image to Size - (1100, 1031)\n",
            "Width exceeds boundary, adjusting overlay image with width / height - 775 / 726 to Size - (775, 726)\n",
            "Generated banner count 3 of 3... /content/demo/output/Banner_Processed/Test2_3_3110041937.png\n",
            "\n",
            "          ['Test2'],\n",
            "          ['Template1'],\n",
            "          Party. Party. Party,\n",
            "          ,\n",
            "          Party unlimited at Blore for this new year, we promise so much fun as we head into 2025. Its gonna be awesome......,\n",
            "          1000 Rs,\n",
            "          50% off,\n",
            "          Bring your friends,\n",
            "          BOOK NOW,\n",
            "          ,\n",
            "          Graphics1.png,\n",
            "          ,\n",
            "          \n",
            "Generating banner count 1 of 3... /content/demo/output/Banner_Processed/Test2_1_3110042017.png\n",
            "Original size of overlay image /content/demo/output/Actors_Processed/NoBg_Test2_2_3110032005.png, Aspect Ratio - 0.9787946428571429, Size - (1920, 1080)\n",
            "Resized overlay image to Size - (1009, 1031)\n",
            "Width exceeds boundary, adjusting overlay image with width / height - 775 / 791 to Size - (775, 791)\n",
            "Original size of overlay image /content/demo/input/Artefacts/Graphics/Graphics1.png, Aspect Ratio - 2.7954070981210855, Size - (1920, 1080)\n",
            "Resized overlay image to Size - (382, 137)\n",
            "Processing text 1000 Rs with initial font size 100\n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Final text 1000 Rs with font size 72\n",
            "Processing text 50% off with initial font size 120\n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Final text 50% off with font size 114\n",
            "Processing text Bring your friends with initial font size 25\n",
            "Final text Bring your friends with font size 25\n",
            "Processing text BOOK NOW with initial font size 35\n",
            "Final text BOOK NOW with font size 35\n",
            "Generated banner count 1 of 3... /content/demo/output/Banner_Processed/Test2_1_3110042017.png\n",
            "Generating banner count 2 of 3... /content/demo/output/Banner_Processed/Test2_2_3110042022.png\n",
            "Original size of overlay image /content/demo/output/Actors_Processed/NoBg_Test2_3_3110032006.png, Aspect Ratio - 1.0751708428246014, Size - (1920, 1080)\n",
            "Resized overlay image to Size - (1108, 1031)\n",
            "Width exceeds boundary, adjusting overlay image with width / height - 775 / 720 to Size - (775, 720)\n",
            "Original size of overlay image /content/demo/input/Artefacts/Graphics/Graphics1.png, Aspect Ratio - 2.7954070981210855, Size - (1920, 1080)\n",
            "Resized overlay image to Size - (382, 137)\n",
            "Processing text 1000 Rs with initial font size 100\n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Final text 1000 Rs with font size 72\n",
            "Processing text 50% off with initial font size 120\n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Final text 50% off with font size 114\n",
            "Processing text Bring your friends with initial font size 25\n",
            "Final text Bring your friends with font size 25\n",
            "Processing text BOOK NOW with initial font size 35\n",
            "Final text BOOK NOW with font size 35\n",
            "Generated banner count 2 of 3... /content/demo/output/Banner_Processed/Test2_2_3110042022.png\n",
            "Generating banner count 3 of 3... /content/demo/output/Banner_Processed/Test2_3_3110042026.png\n",
            "Original size of overlay image /content/demo/output/Actors_Processed/NoBg_Test2_1_3110032004.png, Aspect Ratio - 1.0669642857142858, Size - (1920, 1080)\n",
            "Resized overlay image to Size - (1100, 1031)\n",
            "Width exceeds boundary, adjusting overlay image with width / height - 775 / 726 to Size - (775, 726)\n",
            "Original size of overlay image /content/demo/input/Artefacts/Graphics/Graphics1.png, Aspect Ratio - 2.7954070981210855, Size - (1920, 1080)\n",
            "Resized overlay image to Size - (382, 137)\n",
            "Processing text 1000 Rs with initial font size 100\n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Final text 1000 Rs with font size 72\n",
            "Processing text 50% off with initial font size 120\n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Optimizing fontsize to fit, reducing.. \n",
            "Final text 50% off with font size 114\n",
            "Processing text Bring your friends with initial font size 25\n",
            "Final text Bring your friends with font size 25\n",
            "Processing text BOOK NOW with initial font size 35\n",
            "Final text BOOK NOW with font size 35\n",
            "Generated banner count 3 of 3... /content/demo/output/Banner_Processed/Test2_3_3110042026.png\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7861 <> https://436fb404437a1c8dcc.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    }
  ]
}